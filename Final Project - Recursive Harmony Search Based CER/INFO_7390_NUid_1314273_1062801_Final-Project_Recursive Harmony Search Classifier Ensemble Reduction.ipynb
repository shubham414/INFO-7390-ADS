{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Neu](https://user-images.githubusercontent.com/59803099/102694091-ca79cf80-41ec-11eb-8baf-fa765175202c.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INFO 7390 – Advances in  Data Sciences  & Architecture\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Name: Recursive Harmony Search Based Classifier Ensemble Reduction\n",
    "\n",
    "## Team Members: Shalini Chandra (001062801) & Shubham Mahajan (001314273)\n",
    "                           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project objective:\n",
    "### Improve accuracy, diversity and reduce memory and storage requirement of ensemble classifier by eliminating redundancy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract\n",
    "In recent times classifier ensembles have become a mainstay in data mining and machine learning. The combination\n",
    "of several classifiers generally results in better performance and accuracy as compared to a single classifier. There are many\n",
    "different methods and techniques for constructing ensembles. Most of the time however, when these ensemble classifiers are\n",
    "constructed, the data used in the construction of ensemble classifiers becomes redundant. This redundant data results in\n",
    "a loss of accuracy and an increase in memory and system overhead. Therefore by removing this redundant data we can\n",
    "reduce the memory and system overhead as well as obtain an increase in accuracy. The redundant data can be eliminated by\n",
    "using a technique called feature selection. Feature selection is used to select the most relevant features while performing any\n",
    "task. There are many different feature selection algorithms such as memetic algorithms, sub-modular feature selection, etc. The\n",
    "feature selection technique can be used to choose the relevant data and eliminate the redundant data. The way to eliminate\n",
    "redundant data in ensemble classifiers is to perform classifier ensemble reduction. This paper discusses using feature selection and in particular employing recursive harmony search to perform classifier ensemble reduction via feature selection. The final ensemble classifier will be a reduced set of the original ensemble\n",
    "classifier, while maintaining diversity and accuracy of the original\n",
    "one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset \n",
    "The recursive harmony search feature selection algorithm  was tested against 2 datasets: <br>\n",
    "- The bank dataset (source: https://archive.ics.uci.edu/ml/datasets/bank+marketing)\n",
    "- The heart dataset (source: https://archive.ics.uci.edu/ml/datasets/heart+disease)\n",
    "\n",
    "This notebook specifically shows implemtation for the bank dataset. Algorithm has been tested against the heart dataset also, the result of which are attached at the end of this notebook. <br>\n",
    "For each dataset, we tested the performance with and without applying the recursive harmony search feature selection algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "● Ensemble learning: A machine learning approach where multiple classifiers are trained to solve\n",
    "the same problem.\n",
    "\n",
    "● The main objective of ensemble classifiers is to improve the performance of stand alone\n",
    "classifiers.\n",
    "\n",
    "● Problem: Redundant classifiers and redundant data.\n",
    "\n",
    "● Consequence:\n",
    "\n",
    "  - No improvement in accuracy and diversity.\n",
    "  - Increased training and testing time.\n",
    "\n",
    "● Therefore the time and data constraints result in a significant overhead to system memory and\n",
    "run time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Harmony Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "As we know, when musicians compose the harmony, they usually try various possible combinations of the music pitches stored in their memory. This search for the perfect harmony is indeed analogous to the procedure of finding the optimal solutions to engineering problems. The HS method is actually inspired by the working principles of the harmony improvisation. The pseudocode of the HS is given in Algorithm 1.\n",
    "\n",
    "\n",
    "![Algo](https://user-images.githubusercontent.com/59803099/102680716-d2a02380-4188-11eb-932d-b4c65de4eabb.JPG)\n",
    "\n",
    "\n",
    "Harmony search is a meta heuristic algorithm which is based on finding a solution vector to optimize the cost function of a given optimization problem.\n",
    "\n",
    "● Essentially harmony search is selecting the set of notes (set of features) that produce the best\n",
    "harmony (global optimum).\n",
    "\n",
    "● The musician is the decision variable, the musician decides whether a note should be included in\n",
    "the harmony or not. The harmony (feature subset) is composed of notes that the musicians decide\n",
    "on.\n",
    "\n",
    "● Evaluate the feature subsets to identify the best harmony that is produced by the decisions of the\n",
    "musicians."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Harmony Search Feature Selection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "● The feature selection algorithm to perform classifier ensemble reduction is inspired from the\n",
    "harmony search algorithm.\n",
    "\n",
    "● The notes are the base classifiers and the harmony is the ensemble classifier.\n",
    "\n",
    "● The idea is that the musician will select whether to use a base model or not, that is whether the base model should be included in the group of classifiers forming the ensemble classifier.\n",
    "\n",
    "● Problem: Reliance on a randomly initialized harmony search matrix, which could lead to a\n",
    "suboptimal solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recursive Harmony Search Feature Selection\n",
    "\n",
    "● To overcome the drawback we proposed an extension to the harmony search feature selection\n",
    "algorithm.\n",
    "\n",
    "● The recursive harmony search feature selection algorithm reduces the reliance of the harmony\n",
    "search feature selection algorithm on the initial matrix.\n",
    "\n",
    "● Recursive harmony search feature selection initializes multiple harmony matrices and\n",
    "evaluates these matrices recursively (using harmony search) to find the optimal matrix across\n",
    "all the initial matrices.\n",
    "\n",
    "● This final matrix leads to an optimal solution as the reliance on the randomly initialized\n",
    "harmony search matrix is vastly reduced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembling\n",
    "\n",
    "Ensemble learning helps improve machine learning results by combining several models. This approach allows the production of better predictive performance compared to a single model. That is why ensemble methods placed first in many prestigious machine learning competitions, such as the Netflix Competition, KDD 2009, and Kaggle.\n",
    "The Statsbot team wanted to give you the advantage of this approach and asked a data scientist, Vadim Smolyakov, to dive into three basic ensemble learning techniques.\n",
    "\n",
    "Ensemble methods are meta-algorithms that combine several machine learning techniques into one predictive model in order to decrease variance (bagging), bias (boosting), or improve predictions (stacking).\n",
    "Ensemble methods can be divided into two groups:\n",
    "\n",
    "- sequential ensemble methods where the base learners are generated sequentially (e.g. AdaBoost).\n",
    "The basic motivation of sequential methods is to exploit the dependence between the base learners. The overall performance can be boosted by weighing previously mislabeled examples with higher weight.\n",
    "- parallel ensemble methods where the base learners are generated in parallel (e.g. Random Forest).\n",
    "The basic motivation of parallel methods is to exploit independence between the base learners since the error can be reduced dramatically by averaging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import category_encoders as ce\n",
    "from sklearn import datasets, linear_model, preprocessing\n",
    "from sklearn.model_selection import learning_curve, GridSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import joblib\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, f1_score, log_loss, accuracy_score, \\\n",
    "mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from joblib import Parallel, delayed\n",
    "from functools import partial\n",
    "np.random.seed(1338)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_set(metric):\n",
    "    \n",
    "    global metric_score\n",
    "    global metric_grid_search\n",
    "    metric_functions = {'roc_auc_score' : [roc_auc_score, 'roc_auc'], 'average_precision_score' : \n",
    "                        [average_precision_score, 'average_precision'], 'f1_score' : [f1_score, 'f1'],\n",
    "                        'log_loss' : [log_loss, 'log_loss'], 'accuracy_score' : [accuracy_score, 'accuracy'],\n",
    "                        'mean_absolute_error' : [mean_absolute_error,'mean_absolute_error'],\n",
    "                        'mean_squared_error':[mean_squared_error, 'mean_squared_error'],\n",
    "                        'r2_score' : [r2_score, 'r2']\n",
    "                        }\n",
    "    \n",
    "    metric_score = metric_functions[metric][0]\n",
    "    metric_grid_search = metric_functions[metric][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_import(data, label_output, split = True, stratify = True, split_size = 0.3):\n",
    "    \n",
    "    global Data\n",
    "    Data = data\n",
    "    \n",
    "    #Reading the data, into a Data Frame.\n",
    "    global target_label\n",
    "    target_label = label_output\n",
    "\n",
    "    #Selcting the columns of string data type\n",
    "    names = data.select_dtypes(include = ['object'])\n",
    "    \n",
    "    #Converting string categorical variables to integer categorical variables.\n",
    "    label_encode(names.columns.tolist())\n",
    "    \n",
    "    if(target_label in names):\n",
    "        \n",
    "        columns = names.drop([target_label],axis=1).columns.tolist()\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        columns = names\n",
    "        \n",
    "    #This function intializes the dataframes that will be used later in the program\n",
    "    #data_initialize()\n",
    "    \n",
    "    #Splitting the data into to train and test sets, according to user preference\n",
    "    if(split == True):\n",
    "        \n",
    "        test_data = data_split(stratify,split_size)\n",
    "        return test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that encodes the string values to numerical values.\n",
    "def label_encode(column_names):\n",
    "    \n",
    "    global Data\n",
    "    #Encoding the data, encoding the string values into numerical values.\n",
    "    encoder = ce.OrdinalEncoder(cols = column_names, verbose = 1)\n",
    "    Data = encoder.fit_transform(Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data For Ensembling (Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The dataframes will be used in the training phase of the ensemble models\n",
    "def second_level_train_data(predict_list, cross_val_X, cross_val_Y):\n",
    "    \n",
    "    #Converting the list of predictions into a dataframe, which will be used to train the stacking model.\n",
    "    global stack_X\n",
    "    stack_X = pd.DataFrame()\n",
    "    stack_X = stack_X.append(build_data_frame(predict_list))\n",
    "    \n",
    "    #Building a list that contains all the raw features, used as cross validation data for the base models.\n",
    "    global raw_features_X\n",
    "    raw_features_X = pd.DataFrame()\n",
    "    raw_features_X = raw_features_X.append(cross_val_X,ignore_index=True)\n",
    "    \n",
    "    #The data frame will contain the predictions and raw features  of the base models, for training the blending\n",
    "    #model\n",
    "    global blend_X\n",
    "    blend_X = pd.DataFrame()\n",
    "    blend_X = pd.concat([raw_features_X, stack_X], axis = 1, ignore_index = True)\n",
    "    \n",
    "    #Storing the cross validation dataset labels in the variable stack_Y, \n",
    "    #which will be used later to train the stacking and blending models.\n",
    "    global stack_Y\n",
    "    stack_Y = cross_val_Y  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data For Ensembling (Testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The dataframes will be used in the testing phase of the ensemble models\n",
    "def second_level_test_data(predict_list, test_X, test_Y):\n",
    "    \n",
    "    #Converting the list of predictions into a dataframe, which will be used to test the stacking model.\n",
    "    global test_stack_X\n",
    "    test_stack_X = pd.DataFrame()\n",
    "    test_stack_X = test_stack_X.append(build_data_frame(predict_list))\n",
    "    \n",
    "    #Building a list that contains all the raw features, used as test data for the base models.\n",
    "    global test_raw_features_X\n",
    "    test_raw_features_X = pd.DataFrame()\n",
    "    test_raw_features_X = test_raw_features_X.append(test_X,ignore_index=True)\n",
    "    \n",
    "    #The data frame will contain the predictions and raw features of the base models, for testing the blending\n",
    "    #model\n",
    "    global test_blend_X\n",
    "    test_blend_X = pd.DataFrame()\n",
    "    test_blend_X = pd.concat([test_raw_features_X, test_stack_X], axis = 1, ignore_index = True)\n",
    "    \n",
    "    #Storing the cross validation dataset labels in the variable stack_Y, \n",
    "    #which will be used later to test the stacking and blending models.\n",
    "    global test_stack_Y\n",
    "    test_stack_Y = test_Y  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data into training and testing datasets\n",
    "def data_split(stratify, split_size):\n",
    "    \n",
    "    global Data\n",
    "    \n",
    "    #Stratified Split\n",
    "    if(stratify == True):\n",
    "        Data, test = train_test_split(Data, test_size = split_size, stratify = Data[target_label],random_state = 0)\n",
    "        \n",
    "    #Random Split\n",
    "    else:\n",
    "        Data, test = train_test_split(Data, test_size = split_size,random_state = 0) \n",
    "        \n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function is used to convert the predictions of the base models (numpy array) into a DataFrame.\n",
    "def build_data_frame(data):\n",
    "    \n",
    "    data_frame = pd.DataFrame(data).T\n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trains the Decision Tree model. Performing a grid search to select the optimal parameter values\n",
    "def train_decision_tree(train_X, train_Y, parameters_decision_tree):\n",
    "    \n",
    "    decision_tree_model = DecisionTreeClassifier()      \n",
    "    model_gs = GridSearchCV(decision_tree_model, parameters_decision_tree, scoring = metric_grid_search)\n",
    "    model_gs.fit(train_X,train_Y)\n",
    "    return model_gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicts the output on a set of data, the built model is passed as a parameter, which is used to predict\n",
    "def predict_decision_tree(data_X, data_Y, decision_tree):\n",
    "    \n",
    "    predicted_values = decision_tree.predict_proba(data_X)[:, 1]\n",
    "    metric = metric_score(data_Y, predicted_values)\n",
    "    \n",
    "    return [metric,predicted_values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameter_set_decision_tree(criterion = ['gini'], splitter = ['best'], max_depth = [None],\\\n",
    "                                min_samples_split = [2], min_samples_leaf = [1], min_weight_fraction_leaf = [0.0],\\\n",
    "                                max_features = [None], random_state = [None], max_leaf_nodes = [None],\\\n",
    "                                class_weight = [None], presort = [False]):\n",
    "    \n",
    "    parameters_decision_tree = {}\n",
    "    parameters_decision_tree['criterion'] = criterion\n",
    "    parameters_decision_tree['splitter'] = splitter\n",
    "    parameters_decision_tree['max_depth'] = max_depth\n",
    "    parameters_decision_tree['min_samples_split'] = min_samples_split\n",
    "    parameters_decision_tree['min_samples_leaf'] = min_samples_leaf\n",
    "    parameters_decision_tree['min_weight_fraction_leaf'] = min_weight_fraction_leaf\n",
    "    parameters_decision_tree['max_features'] = max_features\n",
    "    parameters_decision_tree['random_state'] = random_state\n",
    "    parameters_decision_tree['max_leaf_nodes'] = max_leaf_nodes\n",
    "    parameters_decision_tree['class_weight'] = class_weight\n",
    "    parameters_decision_tree['presort'] = presort\n",
    "    \n",
    "    return parameters_decision_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trains the Random Forest model. Performing a grid search to select the optimal parameter values\n",
    "def train_random_forest(train_X, train_Y, parameters_random_forest):\n",
    "    \n",
    "    random_forest_model = RandomForestClassifier()\n",
    "    model_gs = GridSearchCV(random_forest_model, parameters_random_forest, scoring = metric_grid_search)\n",
    "    model_gs.fit(train_X,train_Y)\n",
    "    return model_gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicts the output on a set of data, the built model is passed as a parameter, which is used to predict\n",
    "def predict_random_forest(data_X, data_Y, random_forest):\n",
    "    \n",
    "    predicted_values = random_forest.predict_proba(data_X)[:, 1]\n",
    "    metric = metric_score(data_Y, predicted_values)\n",
    "    \n",
    "    return [metric,predicted_values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters for random forest. To perform hyper parameter optimisation a list of multiple elements can be entered\n",
    "#and the optimal value in that list will be picked using grid search\n",
    "def parameter_set_random_forest(n_estimators = [10], criterion = ['gini'], max_depth = [None],\\\n",
    "                                min_samples_split = [2], min_samples_leaf = [1], min_weight_fraction_leaf = [0.0],\\\n",
    "                                max_features = ['auto'], max_leaf_nodes = [None], bootstrap = [True],\\\n",
    "                                oob_score = [False], random_state = [None], verbose = [0],warm_start = [False],\\\n",
    "                                class_weight = [None]):\n",
    "    \n",
    "    parameters_random_forest = {}\n",
    "    parameters_random_forest['criterion'] = criterion\n",
    "    parameters_random_forest['n_estimators'] = n_estimators\n",
    "    parameters_random_forest['max_depth'] = max_depth\n",
    "    parameters_random_forest['min_samples_split'] = min_samples_split\n",
    "    parameters_random_forest['min_samples_leaf'] = min_samples_leaf\n",
    "    parameters_random_forest['min_weight_fraction_leaf'] = min_weight_fraction_leaf\n",
    "    parameters_random_forest['max_features'] = max_features\n",
    "    parameters_random_forest['random_state'] = random_state\n",
    "    parameters_random_forest['max_leaf_nodes'] = max_leaf_nodes\n",
    "    parameters_random_forest['class_weight'] = class_weight\n",
    "    parameters_random_forest['bootstrap'] = bootstrap\n",
    "    parameters_random_forest['oob_score'] = oob_score\n",
    "    parameters_random_forest['warm_start'] = warm_start\n",
    "    \n",
    "    return parameters_random_forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trains the Linear Regression model. Performing a grid search to select the optimal parameter values\n",
    "def train_linear_regression(train_X, train_Y, parameters_linear_regression):\n",
    "    \n",
    "    linear_regression_model = linear_model.LinearRegression()\n",
    "    train_X=StandardScaler().fit_transform(train_X)\n",
    "    model_gs = GridSearchCV(linear_regression_model, parameters_linear_regression,\\\n",
    "                                        scoring = metric_grid_search)\n",
    "    model_gs.fit(train_X,train_Y)\n",
    "    return model_gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicts the output on a set of data, the built model is passed as a parameter, which is used to predict\n",
    "def predict_linear_regression(data_X, data_Y, linear_regression):\n",
    "    \n",
    "    data_X = StandardScaler().fit_transform(data_X)\n",
    "    predicted_values = linear_regression.predict(data_X)\n",
    "    metric = metric_score(data_Y, predicted_values)\n",
    "    \n",
    "    return [metric,predicted_values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters for linear regression. To perform hyper parameter optimisation a list of multiple elements can be entered\n",
    "#and the optimal value in that list will be picked using grid search\n",
    "def parameter_set_linear_regression(fit_intercept = [True], normalize = [False], copy_X = [True]):\n",
    "    \n",
    "    parameters_linear_regression = {}\n",
    "    parameters_linear_regression['fit_intercept'] = fit_intercept\n",
    "    parameters_linear_regression['normalize'] = normalize\n",
    "    \n",
    "    return parameters_linear_regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trains the Logistic Regression  model. Performing a grid search to select the optimal parameter values\n",
    "def train_logistic_regression(train_X, train_Y, parameters_logistic_regression):\n",
    "\n",
    "    logistic_regression_model = linear_model.LogisticRegression()\n",
    "    #train_X=StandardScaler().fit_transform(train_X)\n",
    "    model_gs = GridSearchCV(logistic_regression_model, parameters_logistic_regression,\\\n",
    "                                        scoring = metric_grid_search)\n",
    "    model_gs.fit(train_X,train_Y)\n",
    "    return model_gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicts the output on a set of data, the built model is passed as a parameter, which is used to predict\n",
    "def predict_logistic_regression(data_X, data_Y, logistic_regression):\n",
    "    \n",
    "    #data_X = StandardScaler().fit_transform(data_X)\n",
    "    predicted_values = logistic_regression.predict_proba(data_X)[:, 1]\n",
    "    \n",
    "    if(metric_grid_search in ['f1', 'log_loss', 'accuracy', 'mean_squared_error', 'mean_absolute_error', 'r2']):\n",
    "        \n",
    "        predictions = logistic_regression.predict(data_X)\n",
    "        metric = metric_score(data_Y, predictions)\n",
    "        \n",
    "    else :\n",
    "        \n",
    "        metric = metric_score(data_Y, predicted_values)\n",
    "    \n",
    "    return [metric,predicted_values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters for logistic regression. To perform hyper parameter optimisation a list of multiple elements can be entered\n",
    "#And the optimal value in that list will be picked using grid search\n",
    "def parameter_set_logistic_regression(penalty = ['l2'], dual = [False], tol = [0.0001], C = [1.0],\\\n",
    "                                      fit_intercept = [True], intercept_scaling = [1], class_weight = [None],\\\n",
    "                                      random_state = [None], solver = ['liblinear'], max_iter = [100],\\\n",
    "                                      multi_class = ['ovr'], verbose = [0], warm_start = [False]):\n",
    "    \n",
    "    parameters_logistic_regression = {}\n",
    "    parameters_logistic_regression['penalty'] = penalty\n",
    "    parameters_logistic_regression['dual'] = dual\n",
    "    parameters_logistic_regression['tol'] = tol\n",
    "    parameters_logistic_regression['C'] = C\n",
    "    parameters_logistic_regression['fit_intercept'] = fit_intercept\n",
    "    parameters_logistic_regression['intercept_scaling'] = intercept_scaling\n",
    "    parameters_logistic_regression['class_weight'] = class_weight\n",
    "    parameters_logistic_regression['solver'] = solver\n",
    "    parameters_logistic_regression['max_iter'] = max_iter\n",
    "    parameters_logistic_regression['multi_class'] = multi_class\n",
    "    parameters_logistic_regression['warm_start'] = warm_start\n",
    "    \n",
    "    return parameters_logistic_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters for logistic regression. To perform hyper parameter optimisation a list of multiple elements can be entered\n",
    "#And the optimal value in that list will be picked using grid search\n",
    "def parameter_set_stacking(penalty = ['l2'], dual = [False], tol = [0.0001], C = [1.0],\\\n",
    "                                      fit_intercept = [True], intercept_scaling = [1], class_weight = [None],\\\n",
    "                                      random_state = [None], solver = ['liblinear'], max_iter = [100],\\\n",
    "                                      multi_class = ['ovr'], verbose = [0], warm_start = [False]):\n",
    "    \n",
    "    parameters_stacking = {}\n",
    "    parameters_stacking['penalty'] = penalty\n",
    "    parameters_stacking['dual'] = dual\n",
    "    parameters_stacking['tol'] = tol\n",
    "    parameters_stacking['C'] = C\n",
    "    parameters_stacking['fit_intercept'] = fit_intercept\n",
    "    parameters_stacking['intercept_scaling'] = intercept_scaling\n",
    "    parameters_stacking['class_weight'] = class_weight\n",
    "    parameters_stacking['solver'] = solver\n",
    "    parameters_stacking['max_iter'] = max_iter\n",
    "    parameters_stacking['multi_class'] = multi_class\n",
    "    parameters_stacking['warm_start'] = warm_start\n",
    "    \n",
    "    return parameters_stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The stacked ensmeble will be trained by using one or more of the base model algorithms\n",
    "#The function of the base model algorithm that will be used to train will be passed as the\n",
    "#model_function parameter and the parameters required to train the algorithm/model will be passed as the\n",
    "#model_parameters parameter\n",
    "def train_stack(data_X, data_Y, model_function, model_parameters):\n",
    "    \n",
    "    model = model_function(data_X, data_Y, model_parameters)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicts the output on a set of stacked data, after the stacked model has been built by using a base model\n",
    "#algorithm, hence we need the predict funcction of that base model algorithm to get the predictions\n",
    "#The predict function of the base model is passed as the predict_function parameter and its respective model is \n",
    "#passed as the model parameter\n",
    "def predict_stack(data_X, data_Y, predict_function, model):\n",
    "    \n",
    "    metric,predicted_values = predict_function(data_X, data_Y, model)\n",
    "    return [metric,predicted_values]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The blending ensmeble will be trained by using one or more of the base model algorithms\n",
    "#The function of the base model algorithm that will be used to train will be passed as the\n",
    "#model_function parameter and the parameters required to train the algorithm/model will be passed as the\n",
    "#model_parameters parameter\n",
    "def train_blend(data_X, data_Y, model_function, model_parameters):\n",
    "    \n",
    "    model = model_function(blend_X, data_Y, model_parameters)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicts the output on a set of blended data, after the blending model has been built by using a base model\n",
    "#algorithm, hence we need the predict function of that base model algorithm to get the predictions\n",
    "#The predict function of the base model is passed as the predict_function parameter and its respective model is \n",
    "#passed as the model parameter\n",
    "def predict_blend(data_X, data_Y, predict_function, model):\n",
    "    \n",
    "    metric,predicted_values = predict_function(test_blend_X, data_Y, model)\n",
    "    return [metric,predicted_values]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training & Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constructing a list (train_model_list) that contains a tuple for each base model, the tuple contains the name of \n",
    "#the function that trains the base model, and the paramters for training the base model. \n",
    "\n",
    "#Constructing a list (predict_model_list) that contains a tuple for each base model, the tuple contains the name of \n",
    "#the function that computes the predictions for the base model.\n",
    "\n",
    "#In the list computed for stacking and blending, the tuples have an additional element which is the train_stack \n",
    "#function or the train_blend function. This is done because different set of data (predictions of base models) \n",
    "#needs to be passed to the base model algorithms. These function enable performing the above procedure\n",
    "\n",
    "#These lists are constructed in such a way to enable the ease of use of the joblib library, i.e the parallel \n",
    "#module/function\n",
    "\n",
    "def construct_model_parameter_list(model_list, parameters_list, stack = False, blend = False):\n",
    "    \n",
    "    model_functions = {#'multi_layer_perceptron' : [train_multi_layer_perceptron,predict_multi_layer_perceptron],\n",
    "                       'decision_tree' : [train_decision_tree,predict_decision_tree],\n",
    "                       'random_forest' : [train_random_forest,predict_random_forest],\n",
    "                       'linear_regression' : [train_linear_regression,predict_linear_regression],\n",
    "                       'logistic_regression' : [train_logistic_regression,predict_logistic_regression]\n",
    "                      }\n",
    "    \n",
    "    train_model_list = list()\n",
    "    predict_model_list = list()\n",
    "    model_parameter_index = 0\n",
    "    \n",
    "    for model in model_list:\n",
    "        \n",
    "        if(stack == True):\n",
    "            \n",
    "            train_model_list.append((model_functions[model][0],parameters_list[model_parameter_index]\\\n",
    "                                         ,train_stack))\n",
    "            predict_model_list.append((model_functions[model][1],predict_stack))\n",
    "            \n",
    "        elif(blend == True):\n",
    "            \n",
    "            train_model_list.append((model_functions[model][0],parameters_list[model_parameter_index]\\\n",
    "                                         ,train_blend))\n",
    "            predict_model_list.append((model_functions[model][1],predict_blend))\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            train_model_list.append((model_functions[model][0],parameters_list[model_parameter_index]))\n",
    "            predict_model_list.append(model_functions[model][1])\n",
    "            \n",
    "        model_parameter_index = model_parameter_index + 1\n",
    "        \n",
    "    return [train_model_list,predict_model_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function computes a list where each element is a tuple that contains the predict function of the base model\n",
    "#along with the corresponding base model object. This is done so that the base model object can be passed to the\n",
    "#predict function as a prameter to compute the predictions when using joblib's parallel module/function. \n",
    "def construct_model_predict_function_list(model_list, models,predict_model_list):\n",
    "    \n",
    "    model_index = 0\n",
    "    model_function_list = list()\n",
    "    for model in model_list:\n",
    "        \n",
    "        model_function_list.append((predict_model_list[model_index],models[model_index]))\n",
    "        model_index = model_index + 1\n",
    "    return model_function_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function calls the respective training and predic functions of the base models.\n",
    "def train_base_models(model_list, parameters_list, save_models = False):\n",
    "    \n",
    "    #print('\\nTRAINING BASE MODELS\\n')\n",
    "    \n",
    "    #Cross Validation using Stratified K Fold\n",
    "    train, cross_val = train_test_split(Data, test_size = 0.5, stratify = Data[target_label],random_state = 0)\n",
    "    \n",
    "    #Training the base models, and calculating AUC on the cross validation data.\n",
    "    #Selecting the data (Traing Data & Cross Validation Data)\n",
    "    train_Y = train[target_label]\n",
    "    train_X = train.drop([target_label],axis=1)\n",
    " \n",
    "    cross_val_Y = cross_val[target_label]\n",
    "    cross_val_X = cross_val.drop([target_label],axis=1)\n",
    "    \n",
    "    #The list of base models the user wants to train.\n",
    "    global base_model_list\n",
    "    base_model_list = model_list\n",
    "\n",
    "    \n",
    "    #No of base models that user wants to train\n",
    "    global no_of_base_models\n",
    "    no_of_base_models = len(base_model_list)\n",
    "    \n",
    "    \n",
    "    #We get the list of base model training functions and predict functions. The elements of the two lists are  \n",
    "    #tuples that have (base model training function,model parameters), (base model predict functions) respectively\n",
    "    [train_base_model_list,predict_base_model_list] = construct_model_parameter_list(base_model_list,\\\n",
    "                                                                                     parameters_list)\n",
    "    \n",
    "\n",
    "    #Training the base models parallely, the resulting models are stored which will be used for cross validation.\n",
    "    models = (Parallel(n_jobs = -1)(delayed(function)(train_X, train_Y, model_parameter)\\\n",
    "                                                   for function, model_parameter in train_base_model_list))\n",
    "\n",
    "    #A list with elements as tuples containing (base model predict function, and its respective model object) is \n",
    "    #returned. This list is used in the next step in the predict_base_models function, the list will be used in\n",
    "    #joblibs parallel module/function to compute the predictions and metric scores of the base models\n",
    "    #Appended in the following manner so it can be used in joblib's parallel module/function\n",
    "    global base_model_predict_function_list\n",
    "    base_model_predict_function_list = construct_model_predict_function_list(base_model_list, models,\\\n",
    "                                                                        predict_base_model_list)\n",
    "    predict_list, data_X, data_Y = predict_base_models(cross_val_X, cross_val_Y,mode = 'train')\n",
    "    \n",
    "    return [predict_list, data_X, data_Y]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction: Base Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_base_models(data_X, data_Y,mode):\n",
    "    \n",
    "    #print('\\nTESTING/CROSS VALIDATION BASE MODELS\\n')\n",
    "    \n",
    "    predict_list = list()\n",
    "\n",
    "    #predict_multi_layer_perceptron = list()\n",
    "    predict_decision_tree = list()\n",
    "    predict_random_forest = list()\n",
    "    predict_linear_regression = list()\n",
    "    predict_logistic_regression = list()\n",
    "    \n",
    "    metric_linear_regression = list()\n",
    "    metric_logistic_regression = list()\n",
    "    metric_decision_tree = list()\n",
    "    metric_random_forest = list()\n",
    "    metric_multi_layer_perceptron = list()\n",
    "    \n",
    "    auc_predict_index = 0\n",
    "    \n",
    "    #Initializing a list which will contain the predictions of the base models and the variables that will\n",
    "    #calculate the metric score\n",
    "    model_predict_metric = {#'multi_layer_perceptron' : [predict_multi_layer_perceptron, metric_multi_layer_perceptron],\n",
    "                       'decision_tree' : [predict_decision_tree, metric_decision_tree],\n",
    "                       'random_forest' : [predict_random_forest, metric_random_forest],\n",
    "                       'linear_regression' : [predict_linear_regression, metric_linear_regression],\n",
    "                       'logistic_regression' : [predict_logistic_regression, metric_logistic_regression]\n",
    "                      }\n",
    "    \n",
    "    #Computing the AUC and Predictions of all the base models on the cross validation data parallely.\n",
    "    auc_predict_cross_val = (Parallel(n_jobs = -1)(delayed(function)(data_X, data_Y, model)\n",
    "                                               for function, model in base_model_predict_function_list))\n",
    "    \n",
    "    #Building the list which will contain all the predictions of the base models and will also display the metric\n",
    "    #scores of the base models\n",
    "    for model in base_model_list:\n",
    "        \n",
    "        #Assigning the predictions and metrics computed for the respective base model\n",
    "        model_predict_metric[model] = auc_predict_cross_val[auc_predict_index][1],\\\n",
    "        auc_predict_cross_val[auc_predict_index][0]\n",
    "        auc_predict_index = auc_predict_index + 1\n",
    "        \n",
    "        if(model == 'multi_layer_perceptron'):\n",
    "            \n",
    "            #This is done only for multi layer perceptron because the predictions returned by the multi layer \n",
    "            #perceptron model is a list of list, the below piece of code converts this nested list into a single\n",
    "            #list\n",
    "            predict_list.append(np.asarray(sum(model_predict_metric[model][0].tolist(), [])))\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            #The below list will contain all the predictions of the base models.\n",
    "            predict_list.append(model_predict_metric[model][0])\n",
    "        \n",
    "        #Printing the name of the base model and its corresponding metric score\n",
    "        print_metric(model,model_predict_metric[model][1])\n",
    "    \n",
    "    return [predict_list, data_X, data_Y]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the second level models parallely\n",
    "def train_ensemble_models(stack_model_list = [], stack_parameters_list = [], blend_model_list = [],\\\n",
    "                              blend_parameters_list = [], perform_weighted_average = False, weights_list = None,\n",
    "                          save_models = False):\n",
    "    \n",
    "    #print('\\nTRAINING ENSEMBLE MODELS\\n')\n",
    "    \n",
    "    global no_of_ensemble_models\n",
    "    \n",
    "    #This list will contain the names of the models/algorithms that have been used as second level models\n",
    "    #This list will be used later in the testing phase for identifying which model belongs to which ensemble\n",
    "    #(stacking or blending), hence the use of dictionaries as elements of the list\n",
    "    #Analogous to the base_model_list\n",
    "    global ensmeble_model_list\n",
    "    ensmeble_model_list = list()\n",
    "    \n",
    "    train_stack_model_list = list() \n",
    "    predict_stack_model_list = list()\n",
    "    train_blend_model_list = list()\n",
    "    predict_blend_model_list = list()\n",
    "    \n",
    "    #The list will be used to train the ensemble models, while using joblib's parallel\n",
    "    train_second_level_models = list() \n",
    "    \n",
    "    #Stacking will not be done if user does not enter the list of models he wants to use for stacking\n",
    "    if(stack_model_list != []):\n",
    "        \n",
    "        #Appending a dictionary that contians key-Stacking and its values/elements are the names of the \n",
    "        #models/algorithms that are used for performing the stacking procedure, this is done so that it will be easy\n",
    "        #to identify the models belonging to the stacking ensemble\n",
    "        ensmeble_model_list.append({'Stacking' : stack_model_list})\n",
    "        \n",
    "        #We get the list of stacked model training functions and predict functions. The elements of the two   \n",
    "        #lists are tuples that have(base model training function,model parameters,train_stack function),\n",
    "        #(base model predict functions,predict_stack function) respectively\n",
    "        [train_stack_model_list,predict_stack_model_list] = construct_model_parameter_list(stack_model_list,\\\n",
    "                                                                                           stack_parameters_list,\n",
    "                                                                                           stack=True)\n",
    "        \n",
    "    #Blending will not be done if user does not enter the list of models he wants to use for blending\n",
    "    if(blend_model_list != []):\n",
    "        \n",
    "        #Appending a dictionary that contians key-Blending and its values/elements are the names of the \n",
    "        #models/algorithms that are used for performing the blending procedure, this is done so that it will be easy\n",
    "        #to identify the models belonging to the blending ensemble\n",
    "        ensmeble_model_list.append({'Blending' : blend_model_list})\n",
    "\n",
    "        #We get the list of blending model training functions and predict functions. The elements of the two   \n",
    "        #lists are tuples that have(base model training function,model parameters,train_blend function),\n",
    "        #(base model predict functions,predict_blend function) respectively\n",
    "        [train_blend_model_list,predict_blend_model_list] = construct_model_parameter_list(blend_model_list,\\\n",
    "                                                                                           blend_parameters_list,\\\n",
    "                                                                                           blend=True)\n",
    "        \n",
    "    #The new list contains either the stacked models or blending models or both or remain empty depending on what \n",
    "    #the user has decided to use\n",
    "    train_second_level_models = train_stack_model_list + train_blend_model_list\n",
    "    \n",
    "   \n",
    "\n",
    "        \n",
    "    no_of_ensemble_models = len(train_second_level_models)\n",
    "\n",
    "    #If weighted average is performed, the last element of models will contain the metric score and weighted average\n",
    "    #predictions, and not a model object. So we use the last element in different ways compared to the other model\n",
    "    #objects\n",
    "    \n",
    "    #Training the ensmeble models parallely \n",
    "    models = Parallel(n_jobs = -1)(delayed(function)(stack_X, stack_Y, model, model_parameter)\\\n",
    "                                        for model, model_parameter, function in train_second_level_models)\n",
    "    \n",
    "    \n",
    "    #A list with elements as tuples containing((base model predict function,predict_stack or predict_blend functions)\n",
    "    #,and its respective base model object) is returned. This list is used in the next step in the   \n",
    "    #predict_ensemble_models function, the list will be used in\n",
    "    #joblibs parallel module/function to compute the predictions and metric score of the ensemble models\n",
    "    #Appended in the following manner so it can be used in joblib's parallel module/function\n",
    "    #Analogous to base_model_predict_function_list\n",
    "    global ensmeble_model_predict_function_list\n",
    "    ensmeble_model_predict_function_list = construct_model_predict_function_list(stack_model_list + blend_model_list,\\\n",
    "                                                                                 models, predict_stack_model_list \n",
    "                                                                                 + predict_blend_model_list)\n",
    "    \n",
    "   \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def harmony_search(predictions, index,harmony_matrix):\n",
    "    \n",
    "    #global harmony_matrix\n",
    "    prediction_list = list()\n",
    "    k = 0\n",
    "    prediction_list=predictions[:]\n",
    "    for j in range(len(harmony_matrix[index])):\n",
    "    \n",
    "        if(harmony_matrix[index][j]==0):\n",
    "            del prediction_list[k]\n",
    "        else:\n",
    "            k = k + 1\n",
    "    return prediction_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def harmony_search_adjust(index,harmony_matrix):\n",
    "    \n",
    "    #global harmony_matrix\n",
    "    global hmcr\n",
    "    global par\n",
    "    \n",
    "    for  i in range (len(harmony_matrix[index])):\n",
    "        \n",
    "        if(random.uniform(0,1)>hmcr):\n",
    "        \n",
    "            harmony_matrix[index][i] = harmony_matrix[random.randint(0,harmony_matrix.shape[0]-1)][i]\n",
    "            if(random.uniform(0,1) > par):\n",
    "                harmony_matrix[index][i] = (harmony_matrix[index][i] + 1)%2\n",
    "                \n",
    "        else:\n",
    "        \n",
    "            harmony_matrix[index][i] = random.randint(0,1)\n",
    "            \n",
    "    if(sum(harmony_matrix[index])==0):\n",
    "        harmony_matrix = np.delete(harmony_matrix, (index), axis=0)\n",
    "        \n",
    "    return harmony_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions: Ensemble Classfier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ensemble_models(data_X, data_Y):\n",
    "    \n",
    "    #print('\\nTESTING ENSEMBLE MODELS\\n')\n",
    "\n",
    "    metric_linear_regression = list()\n",
    "    metric_logistic_regression = list()\n",
    "    metric_decision_tree = list()\n",
    "    metric_random_forest = list()\n",
    "    #metric_multi_layer_perceptron = list()\n",
    "    metric_weighted_average = list()\n",
    "    metric_stacking = list()\n",
    "    metric_blending = list()\n",
    "    \n",
    "    auc_predict_index = 0\n",
    "    \n",
    "    #Initializing a list which will contain the predictions of the base models and the variables that will\n",
    "    #calculate the metric score\n",
    "    model_metric = {#'multi_layer_perceptron' : [metric_multi_layer_perceptron],\n",
    "                       'decision_tree' : [metric_decision_tree],\n",
    "                       'random_forest' : [metric_random_forest],\n",
    "                       'linear_regression' : [metric_linear_regression],\n",
    "                       'logistic_regression' : [metric_logistic_regression]\n",
    "                      }\n",
    "    \n",
    "    #Computing the AUC and Predictions of all the ensmeble models on the test data parallely.\n",
    "    auc_predict_cross_val = (Parallel(n_jobs = -1)(delayed(function[1])(data_X, data_Y, function[0],model)\n",
    "                                               for function, model in ensmeble_model_predict_function_list))\n",
    "    \n",
    "    #ensemble_model_list is a list defined in the train_ensemble_models function, each element of the lsit is a\n",
    "    #dictionary, that contains the name of the ensembling technique (key) and the models assocaited with it(values)\n",
    "    \n",
    "    #So the first for loop gives the dictionary\n",
    "    for ensemble_models in ensmeble_model_list:\n",
    "    \n",
    "        #This for gives the key value pair, key being the name of the ensembling technique, value being a list\n",
    "        #of the models used for that ensemble\n",
    "        for ensemble,models in ensemble_models.items():\n",
    "            \n",
    "            #This for loop gives the iterates through the models present in the models list and asssigns \n",
    "            #the metric score and prints it\n",
    "            for model in models:\n",
    "                \n",
    "                #Assigning the predictions and metrics computed for the respective ensemble model\n",
    "                model_metric[model] = auc_predict_cross_val[auc_predict_index][0]\n",
    "                auc_predict_index = auc_predict_index + 1\n",
    "        \n",
    "                #Printing the name of the ensmeble technique and its model and its corresponding metric score\n",
    "                print_metric(ensemble + \" \" + model,model_metric[model])\n",
    "                return model_metric[model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_models(test_data):\n",
    "    \n",
    "    \n",
    "    #Training the base models, and calculating AUC on the test data.\n",
    "    #Selecting the data (Test Data)\n",
    "    test_Y = test_data[target_label]\n",
    "    test_X = test_data.drop([target_label],axis=1)\n",
    "    \n",
    "    prediction_list = predict_base_models(test_X,test_Y,mode='test')\n",
    "    return prediction_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_models_accuracy():\n",
    "    \n",
    "    accuracy = predict_ensemble_models(test_stack_X,test_stack_Y)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metric(model,metric_score):\n",
    "    a = 2\n",
    "    #Printing the metric score for the corresponding model.\n",
    "    #print (model,'\\n',metric_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_harmony_search(models,params):\n",
    "    \n",
    "    predict_list,data_X,data_Y = train_base_models(models,params)\n",
    "    second_level_train_data(predict_list, data_X, data_Y)\n",
    "    train_ensemble_models(['logistic_regression'],[param_l2])\n",
    "    test_predictions,test_data_X,test_data_Y = test_models(data_test)\n",
    "    second_level_test_data(test_predictions, test_data_X, test_data_Y)\n",
    "    accuracy = test_models_accuracy()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_models(init_models,params,harmony_matrix):\n",
    "    j=0\n",
    "    new_models = list()\n",
    "    new_params = list()\n",
    "    models = init_models[:]\n",
    "    for i in harmony_matrix[0]:\n",
    "        models[j]=models[j]*i \n",
    "        if(models[j]!=''):\n",
    "            new_models.append(models[j])\n",
    "            new_params.append(params[j])\n",
    "        j=j+1\n",
    "    return [new_models,new_params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hs(harmony_matrix):\n",
    "    \n",
    "    global number_of_iterations\n",
    "    \n",
    "    for k in range(number_of_iterations):\n",
    "        worst_index = 0\n",
    "        worst_accuracy = 100\n",
    "        for i in range(harmony_matrix.shape[0]):\n",
    "\n",
    "            prediction_list = harmony_search(predict_list, i,harmony_matrix)\n",
    "            second_level_train_data(prediction_list, data_X, data_Y)\n",
    "            train_ensemble_models(['logistic_regression'],[param_l2])\n",
    "            test_predictions,test_data_X,test_data_Y = test_models(data_test)\n",
    "            test_predictions_list = harmony_search(test_predictions, i,harmony_matrix)\n",
    "            second_level_test_data(test_predictions_list, test_data_X, test_data_Y)\n",
    "            accuracy = test_models_accuracy()\n",
    "\n",
    "            if(accuracy < worst_accuracy):\n",
    "                worst_accuracy = accuracy\n",
    "                worst_index = i\n",
    "        \n",
    "    harmony_matrix = harmony_search_adjust(worst_index,harmony_matrix)\n",
    "\n",
    "    \n",
    "    print(\"Final Harmony Matrix\")\n",
    "    print(harmony_matrix)    \n",
    "    prediction_list = harmony_search(predict_list, 0,harmony_matrix)\n",
    "    second_level_train_data(prediction_list, data_X, data_Y)\n",
    "    train_ensemble_models(['logistic_regression'],[param_l2])\n",
    "    test_predictions,test_data_X,test_data_Y = test_models(data_test)\n",
    "    test_predictions_list = harmony_search(test_predictions, 0,harmony_matrix)\n",
    "    second_level_test_data(test_predictions_list, test_data_X, test_data_Y)\n",
    "    best_accuracy = test_models_accuracy()\n",
    "\n",
    "    hmsize = [1]*(harmony_matrix.shape[0]-1)\n",
    "\n",
    "    for i in hmsize:\n",
    "\n",
    "        prediction_list = harmony_search(predict_list, i,harmony_matrix)\n",
    "        second_level_train_data(prediction_list, data_X, data_Y)\n",
    "        train_ensemble_models(['logistic_regression'],[param_l2])\n",
    "        test_predictions,test_data_X,test_data_Y = test_models(data_test)\n",
    "        test_predictions_list = harmony_search(test_predictions, i,harmony_matrix)\n",
    "        second_level_test_data(test_predictions_list, test_data_X, test_data_Y)\n",
    "        accuracy = test_models_accuracy()\n",
    "\n",
    "        if(accuracy > best_accuracy):\n",
    "            best_accuracy = accuracy\n",
    "            harmony_matrix = np.delete(harmony_matrix, (i-1), axis=0)\n",
    "        else:\n",
    "            harmony_matrix = np.delete(harmony_matrix, (i), axis=0)\n",
    "\n",
    "    print('Optimal Harmony Matrix')\n",
    "    print(harmony_matrix)\n",
    "    return harmony_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPLEMENTATION : BANK DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Implementation Details: <br>\n",
    "    \n",
    "• Base Classifiers: Decision Trees, Logistic Regression,Linear Regression, Random Forest <br>  \n",
    "• Ensemble Classifier: Stacking (Logistic Regression) <br>\n",
    "• Evaluation Metric: roc auc score <br>\n",
    "• Harmony Memory Size: 7 <br>\n",
    "• Harmony Memory Considering Rate: 0.7<br>\n",
    "• Pitch Adjustment Rate: 0.4 <br>\n",
    "    \n",
    "Bank Dataset: <br>\n",
    "• 41189 Instances<br>\n",
    "• 21 Features **<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bank = \"https://raw.githubusercontent.com/shubham414/INFO-7390-ADS/main/Final%20Project%20-%20Recursive%20Harmony%20Search%20Based%20CER/Data%20and%20Result/bank-additional-full.csv\"\n",
    "Data = pd.read_csv(Bank,delimiter=';',header=0)\n",
    "number_of_iterations = 10\n",
    "number_of_rows = 7 # Harmony Memory Size\n",
    "hmcr = 0.7 #Harmony Memory Considering Rate\n",
    "par = 0.4 #Pitch Adjustment Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n"
     ]
    }
   ],
   "source": [
    "data_test = data_import(Data,label_output='y')\n",
    "Data['y']=Data['y']-1\n",
    "data_test['y']=data_test['y']-1\n",
    "metric_set('roc_auc_score')\n",
    "param_dt = parameter_set_decision_tree(max_depth = [6])\n",
    "param_rf = parameter_set_random_forest()\n",
    "param_r = parameter_set_random_forest(n_estimators=[20])\n",
    "param_lr = parameter_set_linear_regression()\n",
    "param_l2 = parameter_set_logistic_regression()\n",
    "param_l = parameter_set_logistic_regression(C=[0.5])\n",
    "param_l1 = parameter_set_logistic_regression(penalty = ['l1'])\n",
    "param_d = parameter_set_decision_tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of models - 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing 8 models with parameters\n",
    "init_models_1 = ['decision_tree','random_forest','linear_regression','logistic_regression','logistic_regression',\\\n",
    "              'random_forest','logistic_regression','decision_tree']\n",
    "init_params_1 = [param_dt, param_rf,param_lr, param_l2, param_l1,param_r,param_l,param_d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1: Initializing  matrices \n",
    "harmony_matrix_1 = np.random.randint(2, size=(number_of_rows, len(init_models_1)))\n",
    "harmony_matrix_2 = np.random.randint(2, size=(number_of_rows, len(init_models_1)))\n",
    "harmony_matrix_3 = np.random.randint(2, size=(number_of_rows, len(init_models_1)))\n",
    "harmony_matrix_4 = np.random.randint(2, size=(number_of_rows, len(init_models_1)))\n",
    "harmony_matrix_5 = np.random.randint(2, size=(number_of_rows, len(init_models_1)))\n",
    "harmony_matrix_6 = np.random.randint(2, size=(number_of_rows, len(init_models_1)))\n",
    "harmony_matrix_7 = np.random.randint(2, size=(number_of_rows, len(init_models_1)))\n",
    "harmony_matrix_8 = np.random.randint(2, size=(number_of_rows, len(init_models_1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harmony Matrix 1\n",
      "[[0 0 0 0 1 0 1 0]\n",
      " [1 0 0 0 1 1 0 0]\n",
      " [1 0 1 1 1 0 0 0]\n",
      " [1 0 0 1 1 1 0 1]\n",
      " [0 1 1 0 0 0 0 1]\n",
      " [0 1 1 0 0 1 1 0]\n",
      " [1 0 0 1 0 1 1 0]]\n",
      "Harmony Matrix 2\n",
      "[[1 1 0 1 1 1 0 0]\n",
      " [0 1 1 1 0 0 1 1]\n",
      " [0 1 1 0 0 1 0 0]\n",
      " [0 1 0 0 0 0 0 0]\n",
      " [1 0 1 0 1 1 0 1]\n",
      " [1 0 1 0 0 0 1 0]\n",
      " [0 0 1 1 0 1 0 1]]\n",
      "Harmony Matrix 3\n",
      "[[0 0 1 1 1 0 1 1]\n",
      " [0 0 1 1 0 1 1 1]\n",
      " [0 0 1 1 0 1 1 1]\n",
      " [0 0 0 1 0 0 1 1]\n",
      " [1 0 0 1 1 1 0 1]\n",
      " [0 0 0 0 1 0 0 1]\n",
      " [0 0 1 1 0 1 1 1]]\n",
      "Harmony Matrix 4\n",
      "[[1 1 1 0 0 1 1 0]\n",
      " [0 1 0 0 1 1 1 1]\n",
      " [1 0 0 0 0 1 1 1]\n",
      " [0 1 1 0 1 1 0 1]\n",
      " [0 0 0 0 0 0 0 1]\n",
      " [0 1 0 1 1 0 0 0]\n",
      " [1 1 1 1 1 1 0 1]]\n",
      "Harmony Matrix 5\n",
      "[[1 1 1 1 0 1 1 1]\n",
      " [0 0 1 1 0 1 1 0]\n",
      " [0 0 1 1 1 1 0 1]\n",
      " [1 1 1 1 0 0 1 1]\n",
      " [1 1 1 0 1 0 1 0]\n",
      " [0 0 1 0 0 1 1 1]\n",
      " [0 0 0 1 0 1 0 1]]\n",
      "Harmony Matrix 6\n",
      "[[0 1 0 1 0 0 1 1]\n",
      " [1 0 0 0 0 0 0 1]\n",
      " [1 1 0 1 0 0 1 0]\n",
      " [0 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 0 0 0 0]\n",
      " [0 1 1 1 0 0 1 0]\n",
      " [0 0 1 0 1 1 1 1]]\n",
      "Harmony Matrix 7\n",
      "[[0 0 1 0 0 1 1 1]\n",
      " [1 1 0 1 1 0 1 0]\n",
      " [0 0 1 0 1 1 1 0]\n",
      " [0 1 0 0 0 1 0 0]\n",
      " [1 1 0 1 0 1 0 0]\n",
      " [0 1 1 0 0 0 0 0]\n",
      " [0 0 1 0 1 1 0 0]]\n",
      "Harmony Matrix 8\n",
      "[[0 1 0 0 0 1 0 0]\n",
      " [1 1 1 1 1 0 1 1]\n",
      " [0 1 1 0 1 0 0 1]\n",
      " [1 1 0 0 0 1 1 0]\n",
      " [0 1 1 0 1 1 1 1]\n",
      " [0 0 1 1 1 0 1 1]\n",
      " [1 0 0 1 0 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Harmony Matrix 1\")\n",
    "print(harmony_matrix_1)\n",
    "print(\"Harmony Matrix 2\")\n",
    "print(harmony_matrix_2)\n",
    "print(\"Harmony Matrix 3\")\n",
    "print(harmony_matrix_3)\n",
    "print(\"Harmony Matrix 4\")\n",
    "print(harmony_matrix_4)\n",
    "print(\"Harmony Matrix 5\")\n",
    "print(harmony_matrix_5)\n",
    "print(\"Harmony Matrix 6\")\n",
    "print(harmony_matrix_6)\n",
    "print(\"Harmony Matrix 7\")\n",
    "print(harmony_matrix_7)\n",
    "print(\"Harmony Matrix 8\")\n",
    "print(harmony_matrix_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Harmony Matrix\n",
      "[[0 1 0 0 0 0 0 1]\n",
      " [1 0 0 0 1 1 0 0]\n",
      " [1 0 1 1 1 0 0 0]\n",
      " [1 0 0 1 1 1 0 1]\n",
      " [0 1 1 0 0 0 0 1]\n",
      " [0 1 1 0 0 1 1 0]\n",
      " [1 0 0 1 0 1 1 0]]\n",
      "Optimal Harmony Matrix\n",
      "[[1 0 0 1 1 1 0 1]]\n",
      "Final Harmony Matrix\n",
      "[[1 1 0 1 1 1 0 0]\n",
      " [0 1 1 1 0 0 1 1]\n",
      " [0 1 1 0 0 1 0 0]\n",
      " [1 1 1 1 1 1 1 0]\n",
      " [1 0 1 0 1 1 0 1]\n",
      " [1 0 1 0 0 0 1 0]\n",
      " [0 0 1 1 0 1 0 1]]\n",
      "Optimal Harmony Matrix\n",
      "[[1 1 0 1 1 1 0 0]]\n",
      "Final Harmony Matrix\n",
      "[[0 0 1 1 1 0 1 1]\n",
      " [0 0 1 1 0 1 1 1]\n",
      " [0 0 1 1 0 1 1 1]\n",
      " [0 0 0 1 0 0 1 1]\n",
      " [1 0 0 1 1 1 0 1]\n",
      " [1 0 0 0 0 1 1 0]\n",
      " [0 0 1 1 0 1 1 1]]\n",
      "Optimal Harmony Matrix\n",
      "[[1 0 0 1 1 1 0 1]]\n",
      "Final Harmony Matrix\n",
      "[[1 1 1 0 0 1 1 0]\n",
      " [0 1 0 0 1 1 1 1]\n",
      " [1 0 0 0 0 1 1 1]\n",
      " [0 1 1 0 1 1 0 1]\n",
      " [1 1 1 0 1 1 1 1]\n",
      " [0 1 0 1 1 0 0 0]\n",
      " [1 1 1 1 1 1 0 1]]\n",
      "Optimal Harmony Matrix\n",
      "[[1 0 0 0 0 1 1 1]]\n",
      "Final Harmony Matrix\n",
      "[[1 1 1 1 0 1 1 1]\n",
      " [0 1 1 1 0 1 0 0]\n",
      " [0 0 1 1 1 1 0 1]\n",
      " [1 1 1 1 0 0 1 1]\n",
      " [1 1 1 0 1 0 1 0]\n",
      " [0 0 1 0 0 1 1 1]\n",
      " [0 0 0 1 0 1 0 1]]\n",
      "Optimal Harmony Matrix\n",
      "[[1 1 1 1 0 1 1 1]]\n",
      "Final Harmony Matrix\n",
      "[[0 1 0 1 0 0 1 1]\n",
      " [1 0 1 1 1 1 0 0]\n",
      " [1 1 0 1 0 0 1 0]\n",
      " [0 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 0 0 0 0]\n",
      " [0 1 1 1 0 0 1 0]\n",
      " [0 0 1 0 1 1 1 1]]\n",
      "Optimal Harmony Matrix\n",
      "[[0 1 1 1 1 1 1 1]]\n",
      "Final Harmony Matrix\n",
      "[[0 0 1 0 0 1 1 1]\n",
      " [1 1 0 1 1 0 1 0]\n",
      " [0 0 1 0 1 1 1 0]\n",
      " [0 1 1 0 1 1 0 0]\n",
      " [1 1 0 1 0 1 0 0]\n",
      " [0 1 1 0 0 0 0 0]\n",
      " [0 0 1 0 1 1 0 0]]\n",
      "Optimal Harmony Matrix\n",
      "[[1 1 0 1 0 1 0 0]]\n",
      "Final Harmony Matrix\n",
      "[[0 1 0 0 0 1 0 0]\n",
      " [1 1 1 1 1 0 1 1]\n",
      " [0 1 1 0 1 0 0 1]\n",
      " [1 1 0 0 0 1 1 0]\n",
      " [0 1 1 0 1 1 1 1]\n",
      " [1 1 0 0 0 1 1 0]\n",
      " [1 0 0 1 0 1 0 0]]\n",
      "Optimal Harmony Matrix\n",
      "[[1 1 0 0 0 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "# Step 2: performing harmony search on each individual matrix.\n",
    "# Step 3: The final matrices that are obtained after performing harmony search on the matrices in step 2 will be evaluated.\n",
    "# Step 4: Identifying the optimal matrices for each individual matrix obtained from step 3.\n",
    "\n",
    "predict_list,data_X,data_Y = train_base_models(init_models_1,init_params_1)\n",
    "\n",
    "harmony_matrix_1 = hs(harmony_matrix_1)\n",
    "harmony_matrix_2 = hs(harmony_matrix_2)\n",
    "harmony_matrix_3 = hs(harmony_matrix_3)\n",
    "harmony_matrix_4 = hs(harmony_matrix_4)\n",
    "harmony_matrix_5 = hs(harmony_matrix_5)\n",
    "harmony_matrix_6 = hs(harmony_matrix_6)\n",
    "harmony_matrix_7 = hs(harmony_matrix_7)\n",
    "harmony_matrix_8 = hs(harmony_matrix_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recursive Harmony Matrix\n",
      "[[1 0 0 1 1 1 0 1]\n",
      " [1 1 0 1 1 1 0 0]\n",
      " [1 0 0 1 1 1 0 1]\n",
      " [1 0 0 0 0 1 1 1]\n",
      " [1 1 1 1 0 1 1 1]\n",
      " [0 1 1 1 1 1 1 1]\n",
      " [1 1 0 1 0 1 0 0]\n",
      " [1 1 0 0 0 1 1 0]]\n",
      "Final Harmony Matrix\n",
      "[[1 0 0 1 1 1 0 1]\n",
      " [1 1 0 1 1 1 0 0]\n",
      " [1 0 0 1 1 1 0 1]\n",
      " [1 0 0 0 0 1 1 1]\n",
      " [1 1 1 1 0 1 1 1]\n",
      " [1 0 1 0 0 0 1 1]\n",
      " [1 1 0 1 0 1 0 0]\n",
      " [1 1 0 0 0 1 1 0]]\n",
      "Optimal Harmony Matrix\n",
      "[[1 1 0 1 1 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Step 5:Combined the optimal matrices into a new matrix and performed harmony search on the new matrix to \n",
    "# obtain the final harmony matrix, which is then evaluated to obtain the final optimal matrix.\n",
    "\n",
    "harmony_matrix_rec = np.concatenate((harmony_matrix_1,harmony_matrix_2,harmony_matrix_3,harmony_matrix_4,\\\n",
    "                                    harmony_matrix_5,harmony_matrix_6,harmony_matrix_7,harmony_matrix_8))\n",
    "print(\"Recursive Harmony Matrix\")\n",
    "print(harmony_matrix_rec)\n",
    "harmony_matrix_rec = hs(harmony_matrix_rec)                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final optimal matrix obtained at the end of step 5 is the subset of classifiers that will be used in the ensemble classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In simple words, As you can see here, recursive harmony search algorithm gave us optimal harmony matrix as [[0,0,1,1,0,1,1,0]] where 0 and 1 represent if we have considered the particular model or base class classifier. If you remember, we initialized 8 models here. Out of which, according to optimal harmony matrix, 3rd, 4th, 6th and 7th can achieve same accuracy with less models and cpu runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time 94.00571298599243\n",
      "0.9413353486275559\n"
     ]
    }
   ],
   "source": [
    "#without ensemble classifer reduction\n",
    "import time\n",
    "start = time.time()\n",
    "a = final_harmony_search(init_models_1,init_params_1)\n",
    "print(\"time\",end - start)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9413353486275559]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accu=[]\n",
    "accu.append(a)\n",
    "accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_models_rec,new_params_rec = get_new_models(init_models_1,init_params_1,harmony_matrix_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time 77.79203200340271\n",
      "AUC SCORE: 0.9424847083981948\n"
     ]
    }
   ],
   "source": [
    "#with ensemble classifer reduction\n",
    "import time\n",
    "start = time.time()\n",
    "b = final_harmony_search(new_models_rec,new_params_rec)\n",
    "end = time.time()\n",
    "print(\"time\",end - start)\n",
    "print(\"AUC SCORE:\",b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9424847083981948]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accu_2=[]\n",
    "accu_2.append(b)\n",
    "accu_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Models 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_models_2 = ['decision_tree','random_forest','linear_regression','logistic_regression','logistic_regression',\\\n",
    "              'random_forest','logistic_regression','decision_tree','linear_regression', 'random_forest', \\\n",
    "               'linear_regression','decision_tree','logistic_regression','decision_tree','random_forest',\\\n",
    "               'decision_tree', 'logistic_regression','linear_regression','random_forest','decision_tree', \\\n",
    "                'random_forest','linear_regression','logistic_regression','logistic_regression','random_forest',\\\n",
    "               'linear_regression','decision_tree','logistic_regression','decision_tree','random_forest'\n",
    "              ]\n",
    "init_params_2 = [param_dt, param_rf,param_lr, param_l2, param_l1,\n",
    "               param_r,param_l,param_d,param_lr,param_rf,\n",
    "               param_lr, param_dt,param_l,param_d,param_r,\n",
    "               param_dt, param_l2,param_lr,param_rf,param_d,\n",
    "               param_r,param_lr,param_l2, param_l,param_rf,\n",
    "               param_lr,param_dt,param_l2,param_dt,param_r\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(init_models_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "harmony_matrix_1 = np.random.randint(2, size=(number_of_rows, len(init_models_2)))\n",
    "harmony_matrix_2 = np.random.randint(2, size=(number_of_rows, len(init_models_2)))\n",
    "harmony_matrix_3 = np.random.randint(2, size=(number_of_rows, len(init_models_2)))\n",
    "harmony_matrix_4 = np.random.randint(2, size=(number_of_rows, len(init_models_2)))\n",
    "harmony_matrix_5 = np.random.randint(2, size=(number_of_rows, len(init_models_2)))\n",
    "harmony_matrix_6 = np.random.randint(2, size=(number_of_rows, len(init_models_2)))\n",
    "harmony_matrix_7 = np.random.randint(2, size=(number_of_rows, len(init_models_2)))\n",
    "harmony_matrix_8 = np.random.randint(2, size=(number_of_rows, len(init_models_2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harmony Matrix 1\n",
      "[[1 0 1 0 0 1 1 0 1 0 1 0 0 1 0 1 0 1 0 0 0 0 1 1 1 1 1 1 0 0]\n",
      " [0 1 1 0 1 0 0 0 1 0 1 0 1 1 1 0 1 0 0 0 1 1 1 1 0 1 1 1 0 0]\n",
      " [1 0 0 0 1 1 1 1 1 1 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1 1 1 0 1]\n",
      " [0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 0 1 0 1 1 1 0 0 1 0 0 1 0]\n",
      " [1 0 1 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 0 1 1 1 0 0]\n",
      " [0 1 1 0 0 0 0 0 1 1 0 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1]\n",
      " [0 1 0 0 1 1 1 0 0 1 0 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0]]\n",
      "Harmony Matrix 2\n",
      "[[0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 1 0 0 1 0 0 0 1 0 1 0 1 1 0 1]\n",
      " [1 1 1 1 1 0 1 0 0 1 1 1 1 1 0 0 1 1 0 0 1 1 0 1 1 1 0 1 1 1]\n",
      " [1 1 1 1 0 0 1 0 1 0 1 1 1 0 1 1 0 1 1 0 0 1 1 1 0 0 0 0 1 0]\n",
      " [0 1 1 0 1 0 1 1 1 1 0 1 0 1 0 1 1 1 0 1 1 0 0 1 1 1 0 0 0 0]\n",
      " [0 0 0 1 0 1 0 0 0 1 1 0 1 0 1 1 1 0 0 1 1 1 0 1 1 1 0 1 0 1]\n",
      " [0 1 1 0 1 1 0 1 1 1 0 1 0 1 1 0 0 1 0 0 0 1 1 0 0 0 1 0 1 1]\n",
      " [0 1 1 0 1 0 1 0 1 0 1 0 0 1 0 1 1 1 0 1 0 0 0 1 0 1 1 0 0 1]]\n",
      "Harmony Matrix 3\n",
      "[[0 1 0 1 0 0 1 0 0 1 1 1 0 1 0 0 1 1 0 0 0 1 0 1 0 1 1 0 0 1]\n",
      " [1 1 0 1 1 0 0 1 0 0 0 0 0 1 0 1 1 0 0 0 1 0 1 1 1 1 1 0 0 0]\n",
      " [1 0 1 1 1 0 0 1 0 1 0 1 1 0 0 0 1 0 1 0 0 1 1 1 1 1 0 0 0 0]\n",
      " [0 1 1 0 1 0 0 0 0 1 0 1 1 1 1 0 1 1 0 1 0 0 1 1 0 0 0 1 0 1]\n",
      " [1 1 0 0 1 1 0 0 1 0 0 0 1 0 0 0 1 1 0 0 0 1 1 1 0 0 0 1 1 1]\n",
      " [0 0 1 0 0 0 0 1 1 0 1 1 1 0 0 0 1 1 1 1 0 1 1 1 0 1 1 0 0 0]\n",
      " [0 0 1 1 1 0 1 1 1 1 1 1 0 0 1 0 0 1 1 0 1 0 1 0 0 1 0 1 1 1]]\n",
      "Harmony Matrix 4\n",
      "[[1 1 1 1 1 0 1 0 0 1 1 1 0 0 1 0 1 1 1 0 0 1 0 0 0 0 0 1 0 0]\n",
      " [0 0 1 1 1 0 0 1 1 0 0 1 1 0 1 0 1 1 0 0 1 1 1 1 1 1 1 0 0 1]\n",
      " [0 0 0 1 1 1 0 1 1 1 0 1 0 1 0 0 1 0 1 0 1 1 0 0 1 1 1 1 1 0]\n",
      " [1 0 1 1 0 1 0 1 1 0 0 1 1 0 0 1 0 1 1 1 0 0 0 1 0 0 0 1 0 1]\n",
      " [1 0 1 1 0 0 1 1 1 1 1 0 1 1 0 0 0 1 1 1 0 0 1 0 1 0 1 0 1 0]\n",
      " [0 0 1 1 1 0 1 1 1 0 1 0 0 0 1 0 0 0 0 1 1 1 1 1 1 1 0 1 0 0]\n",
      " [1 1 0 0 1 0 1 0 1 0 1 0 1 1 1 0 0 1 1 0 0 1 1 1 1 1 0 1 0 1]]\n",
      "Harmony Matrix 5\n",
      "[[1 0 0 0 1 0 1 0 0 0 0 1 0 1 1 1 0 1 1 0 0 1 0 0 0 0 1 1 0 0]\n",
      " [1 1 1 0 0 1 1 1 1 0 0 1 0 0 1 1 0 0 1 0 0 1 0 1 0 0 1 0 1 0]\n",
      " [1 1 0 0 1 0 1 1 1 0 0 1 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 0 0]\n",
      " [1 0 1 1 1 0 0 0 0 1 1 1 1 0 0 0 1 0 1 1 0 1 0 1 1 1 0 1 0 0]\n",
      " [0 0 1 0 1 0 1 0 1 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 1 0]\n",
      " [1 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1]\n",
      " [1 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1 0 0 1 1 0 1 1 0 0 0 1 0 1 1]]\n",
      "Harmony Matrix 6\n",
      "[[0 0 1 1 1 1 0 0 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 1 0 1 1]\n",
      " [0 0 0 1 0 1 0 0 0 1 0 1 1 0 1 0 1 1 1 1 0 1 0 0 1 0 1 0 0 0]\n",
      " [0 0 1 0 1 0 1 0 0 0 1 1 0 0 1 0 0 1 0 1 0 0 1 1 1 1 0 1 1 0]\n",
      " [1 1 0 0 1 1 0 1 1 1 0 1 0 0 0 1 1 1 0 0 0 1 1 0 0 0 1 1 0 0]\n",
      " [1 1 0 1 1 0 0 1 1 1 0 1 1 0 1 0 1 1 0 0 1 0 0 1 1 0 1 0 0 0]\n",
      " [1 0 0 1 1 1 0 0 0 1 1 0 0 0 0 0 1 1 1 1 1 0 1 1 0 1 0 0 1 0]\n",
      " [1 0 1 0 1 0 0 1 0 0 1 1 0 1 0 0 0 0 0 1 1 1 1 1 1 1 0 0 1 0]]\n",
      "Harmony Matrix 7\n",
      "[[0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 1 1]\n",
      " [0 1 1 1 1 0 0 0 0 0 1 0 1 0 1 1 1 0 0 0 1 0 1 1 0 0 0 1 1 1]\n",
      " [1 0 1 0 1 1 0 1 0 0 1 1 1 0 1 1 0 1 1 1 0 1 0 0 1 0 1 0 1 1]\n",
      " [1 0 1 1 1 0 1 1 0 0 0 1 1 0 0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 1]\n",
      " [0 0 0 0 0 1 0 1 0 0 0 1 1 0 1 0 0 0 1 0 1 1 0 1 1 1 1 0 0 0]\n",
      " [1 0 1 0 0 0 0 1 0 1 0 0 1 1 1 1 0 0 0 1 1 1 1 1 0 0 1 1 1 0]\n",
      " [1 1 0 1 1 1 0 0 1 0 1 1 1 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0]]\n",
      "Harmony Matrix 8\n",
      "[[1 1 0 0 1 0 1 0 1 0 0 0 0 0 1 0 0 1 1 1 0 0 0 1 1 1 1 0 0 1]\n",
      " [0 0 1 1 0 1 0 1 0 0 1 0 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1 0]\n",
      " [1 0 0 1 1 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 1 0 0 1 0 0 1 0 0]\n",
      " [1 0 1 1 1 1 0 0 1 1 1 0 1 0 1 1 0 1 0 1 0 0 0 0 1 0 0 0 0 1]\n",
      " [0 1 1 1 1 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 1]\n",
      " [0 0 0 0 0 1 0 1 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1]\n",
      " [0 0 1 0 1 0 1 0 1 0 1 0 1 1 0 1 1 1 0 1 0 1 1 1 1 1 0 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Harmony Matrix 1\")\n",
    "print(harmony_matrix_1)\n",
    "print(\"Harmony Matrix 2\")\n",
    "print(harmony_matrix_2)\n",
    "print(\"Harmony Matrix 3\")\n",
    "print(harmony_matrix_3)\n",
    "print(\"Harmony Matrix 4\")\n",
    "print(harmony_matrix_4)\n",
    "print(\"Harmony Matrix 5\")\n",
    "print(harmony_matrix_5)\n",
    "print(\"Harmony Matrix 6\")\n",
    "print(harmony_matrix_6)\n",
    "print(\"Harmony Matrix 7\")\n",
    "print(harmony_matrix_7)\n",
    "print(\"Harmony Matrix 8\")\n",
    "print(harmony_matrix_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Harmony Matrix\n",
      "[[1 0 1 0 0 1 1 0 1 0 1 0 0 1 0 1 0 1 0 0 0 0 1 1 1 1 1 1 0 0]\n",
      " [0 1 1 0 1 0 0 0 1 0 1 0 1 1 1 0 1 0 0 0 1 1 1 1 0 1 1 1 0 0]\n",
      " [0 0 0 0 1 0 1 0 0 1 1 1 0 1 0 1 0 1 1 0 0 1 0 0 1 1 0 1 0 0]\n",
      " [0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 0 1 0 1 1 1 0 0 1 0 0 1 0]\n",
      " [1 0 1 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 0 1 1 1 0 0]\n",
      " [0 1 1 0 0 0 0 0 1 1 0 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1]\n",
      " [0 1 0 0 1 1 1 0 0 1 0 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0]]\n",
      "Optimal Harmony Matrix\n",
      "[[0 1 1 0 0 0 0 0 1 1 0 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1]]\n",
      "Final Harmony Matrix\n",
      "[[0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 1 0 0 1 0 0 0 1 0 1 0 1 1 0 1]\n",
      " [1 1 1 1 1 0 1 0 0 1 1 1 1 1 0 0 1 1 0 0 1 1 0 1 1 1 0 1 1 1]\n",
      " [1 1 1 1 0 0 1 0 1 0 1 1 1 0 1 1 0 1 1 0 0 1 1 1 0 0 0 0 1 0]\n",
      " [0 1 1 0 1 0 1 1 1 1 0 1 0 1 0 1 1 1 0 1 1 0 0 1 1 1 0 0 0 0]\n",
      " [0 0 0 1 0 1 0 0 0 1 1 0 1 0 1 1 1 0 0 1 1 1 0 1 1 1 0 1 0 1]\n",
      " [0 1 1 0 1 1 0 1 1 1 0 1 0 1 1 0 0 1 0 0 0 1 1 0 0 0 1 0 1 1]\n",
      " [1 1 0 0 0 0 1 0 0 0 1 1 1 1 1 0 1 0 0 1 0 0 1 1 1 1 1 1 1 0]]\n",
      "Optimal Harmony Matrix\n",
      "[[0 0 0 1 0 1 0 0 0 1 1 0 1 0 1 1 1 0 0 1 1 1 0 1 1 1 0 1 0 1]]\n",
      "Final Harmony Matrix\n",
      "[[0 1 0 1 0 0 1 0 0 1 1 1 0 1 0 0 1 1 0 0 0 1 0 1 0 1 1 0 0 1]\n",
      " [1 1 0 1 1 0 0 1 0 0 0 0 0 1 0 1 1 0 0 0 1 0 1 1 1 1 1 0 0 0]\n",
      " [1 0 1 1 1 0 0 1 0 1 0 1 1 0 0 0 1 0 1 0 0 1 1 1 1 1 0 0 0 0]\n",
      " [0 1 1 0 1 0 0 0 0 1 0 1 1 1 1 0 1 1 0 1 0 0 1 1 0 0 0 1 0 1]\n",
      " [1 1 0 0 1 1 0 0 1 0 0 0 1 0 0 0 1 1 0 0 0 1 1 1 0 0 0 1 1 1]\n",
      " [0 0 1 0 0 0 1 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0]\n",
      " [0 0 1 1 1 0 1 1 1 1 1 1 0 0 1 0 0 1 1 0 1 0 1 0 0 1 0 1 1 1]]\n",
      "Optimal Harmony Matrix\n",
      "[[0 0 1 0 0 0 1 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0]]\n",
      "Final Harmony Matrix\n",
      "[[1 1 1 1 1 0 1 0 0 1 1 1 0 0 1 0 1 1 1 0 0 1 0 0 0 0 0 1 0 0]\n",
      " [0 0 1 1 1 0 0 1 1 0 0 1 1 0 1 0 1 1 0 0 1 1 1 1 1 1 1 0 0 1]\n",
      " [0 0 0 1 1 1 0 1 1 1 0 1 0 1 0 0 1 0 1 0 1 1 0 0 1 1 1 1 1 0]\n",
      " [1 0 1 0 1 0 0 0 1 1 1 0 1 1 0 1 0 0 0 0 1 0 1 0 1 0 1 1 0 1]\n",
      " [1 0 1 1 0 0 1 1 1 1 1 0 1 1 0 0 0 1 1 1 0 0 1 0 1 0 1 0 1 0]\n",
      " [0 0 1 1 1 0 1 1 1 0 1 0 0 0 1 0 0 0 0 1 1 1 1 1 1 1 0 1 0 0]\n",
      " [1 1 0 0 1 0 1 0 1 0 1 0 1 1 1 0 0 1 1 0 0 1 1 1 1 1 0 1 0 1]]\n",
      "Optimal Harmony Matrix\n",
      "[[0 0 1 1 1 0 0 1 1 0 0 1 1 0 1 0 1 1 0 0 1 1 1 1 1 1 1 0 0 1]]\n",
      "Final Harmony Matrix\n",
      "[[1 0 0 0 1 0 1 0 0 0 0 1 0 1 1 1 0 1 1 0 0 1 0 0 0 0 1 1 0 0]\n",
      " [1 1 1 0 0 1 1 1 1 0 0 1 0 0 1 1 0 0 1 0 0 1 0 1 0 0 1 0 1 0]\n",
      " [1 1 0 0 1 0 1 1 1 0 0 1 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 0 0]\n",
      " [1 0 1 1 1 0 0 0 0 1 1 1 1 0 0 0 1 0 1 1 0 1 0 1 1 1 0 1 0 0]\n",
      " [0 1 1 0 1 1 0 0 0 0 1 0 1 1 0 0 1 1 0 1 1 1 0 0 1 1 0 1 0 0]\n",
      " [1 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1]\n",
      " [1 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1 0 0 1 1 0 1 1 0 0 0 1 0 1 1]]\n",
      "Optimal Harmony Matrix\n",
      "[[1 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1]]\n",
      "Final Harmony Matrix\n",
      "[[1 0 1 0 1 0 1 1 0 0 0 1 0 0 1 1 1 1 1 1 0 1 0 0 1 1 0 0 1 0]\n",
      " [0 0 0 1 0 1 0 0 0 1 0 1 1 0 1 0 1 1 1 1 0 1 0 0 1 0 1 0 0 0]\n",
      " [0 0 1 0 1 0 1 0 0 0 1 1 0 0 1 0 0 1 0 1 0 0 1 1 1 1 0 1 1 0]\n",
      " [1 1 0 0 1 1 0 1 1 1 0 1 0 0 0 1 1 1 0 0 0 1 1 0 0 0 1 1 0 0]\n",
      " [1 1 0 1 1 0 0 1 1 1 0 1 1 0 1 0 1 1 0 0 1 0 0 1 1 0 1 0 0 0]\n",
      " [1 0 0 1 1 1 0 0 0 1 1 0 0 0 0 0 1 1 1 1 1 0 1 1 0 1 0 0 1 0]\n",
      " [1 0 1 0 1 0 0 1 0 0 1 1 0 1 0 0 0 0 0 1 1 1 1 1 1 1 0 0 1 0]]\n",
      "Optimal Harmony Matrix\n",
      "[[0 0 0 1 0 1 0 0 0 1 0 1 1 0 1 0 1 1 1 1 0 1 0 0 1 0 1 0 0 0]]\n",
      "Final Harmony Matrix\n",
      "[[0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 1 1]\n",
      " [0 1 1 1 1 0 0 0 0 0 1 0 1 0 1 1 1 0 0 0 1 0 1 1 0 0 0 1 1 1]\n",
      " [1 0 1 0 1 1 0 1 0 0 1 1 1 0 1 1 0 1 1 1 0 1 0 0 1 0 1 0 1 1]\n",
      " [0 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0 0 0 1 0 0 1 0 0 1 1 1 0 1 0]\n",
      " [0 0 0 0 0 1 0 1 0 0 0 1 1 0 1 0 0 0 1 0 1 1 0 1 1 1 1 0 0 0]\n",
      " [1 0 1 0 0 0 0 1 0 1 0 0 1 1 1 1 0 0 0 1 1 1 1 1 0 0 1 1 1 0]\n",
      " [1 1 0 1 1 1 0 0 1 0 1 1 1 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0]]\n",
      "Optimal Harmony Matrix\n",
      "[[0 0 0 0 0 1 0 1 0 0 0 1 1 0 1 0 0 0 1 0 1 1 0 1 1 1 1 0 0 0]]\n",
      "Final Harmony Matrix\n",
      "[[1 1 0 0 1 0 1 0 1 0 0 0 0 0 1 0 0 1 1 1 0 0 0 1 1 1 1 0 0 1]\n",
      " [0 0 1 1 0 1 0 1 0 0 1 0 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1 0]\n",
      " [1 0 0 1 1 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 1 0 0 1 0 0 1 0 0]\n",
      " [1 0 1 1 1 1 0 0 1 1 1 0 1 0 1 1 0 1 0 1 0 0 0 0 1 0 0 0 0 1]\n",
      " [0 1 1 1 1 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 1]\n",
      " [0 0 0 0 0 1 0 1 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1]\n",
      " [0 0 0 1 1 0 1 1 1 1 0 1 0 0 1 0 0 0 0 1 1 0 0 1 0 1 0 0 1 0]]\n",
      "Optimal Harmony Matrix\n",
      "[[0 0 1 1 0 1 0 1 0 0 1 0 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "predict_list,data_X,data_Y = train_base_models(init_models_2,init_params_2)\n",
    "\n",
    "harmony_matrix_1 = hs(harmony_matrix_1)\n",
    "harmony_matrix_2 = hs(harmony_matrix_2)\n",
    "harmony_matrix_3 = hs(harmony_matrix_3)\n",
    "harmony_matrix_4 = hs(harmony_matrix_4)\n",
    "harmony_matrix_5 = hs(harmony_matrix_5)\n",
    "harmony_matrix_6 = hs(harmony_matrix_6)\n",
    "harmony_matrix_7 = hs(harmony_matrix_7)\n",
    "harmony_matrix_8 = hs(harmony_matrix_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recursive Harmony Matrix\n",
      "[[0 1 1 0 0 0 0 0 1 1 0 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1]\n",
      " [0 0 0 1 0 1 0 0 0 1 1 0 1 0 1 1 1 0 0 1 1 1 0 1 1 1 0 1 0 1]\n",
      " [0 0 1 0 0 0 1 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0]\n",
      " [0 0 1 1 1 0 0 1 1 0 0 1 1 0 1 0 1 1 0 0 1 1 1 1 1 1 1 0 0 1]\n",
      " [1 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1]\n",
      " [0 0 0 1 0 1 0 0 0 1 0 1 1 0 1 0 1 1 1 1 0 1 0 0 1 0 1 0 0 0]\n",
      " [0 0 0 0 0 1 0 1 0 0 0 1 1 0 1 0 0 0 1 0 1 1 0 1 1 1 1 0 0 0]\n",
      " [0 0 1 1 0 1 0 1 0 0 1 0 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1 0]]\n",
      "Final Harmony Matrix\n",
      "[[0 1 1 0 0 0 0 0 1 1 0 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1]\n",
      " [0 0 0 1 0 1 0 0 0 1 1 0 1 0 1 1 1 0 0 1 1 1 0 1 1 1 0 1 0 1]\n",
      " [0 0 1 0 0 0 1 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0]\n",
      " [0 0 1 1 1 0 0 1 1 0 0 1 1 0 1 0 1 1 0 0 1 1 1 1 1 1 1 0 0 1]\n",
      " [1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 0 1 1 0 0 1]\n",
      " [0 0 0 1 0 1 0 0 0 1 0 1 1 0 1 0 1 1 1 1 0 1 0 0 1 0 1 0 0 0]\n",
      " [0 0 0 0 0 1 0 1 0 0 0 1 1 0 1 0 0 0 1 0 1 1 0 1 1 1 1 0 0 0]\n",
      " [0 0 1 1 0 1 0 1 0 0 1 0 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1 0]]\n",
      "Optimal Harmony Matrix\n",
      "[[0 0 0 0 0 1 0 1 0 0 0 1 1 0 1 0 0 0 1 0 1 1 0 1 1 1 1 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "harmony_matrix_rec = np.concatenate((harmony_matrix_1,harmony_matrix_2,harmony_matrix_3,harmony_matrix_4,\\\n",
    "                                    harmony_matrix_5,harmony_matrix_6,harmony_matrix_7,harmony_matrix_8))\n",
    "print(\"Recursive Harmony Matrix\")\n",
    "print(harmony_matrix_rec)\n",
    "harmony_matrix_rec = hs(harmony_matrix_rec)                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time 55.460633754730225\n",
      "0.9414763406030683\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "a_2 = final_harmony_search(init_models_2,init_params_2)\n",
    "end = time.time()\n",
    "print(\"time\",end - start)\n",
    "print(a_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9413353486275559, 0.9414763406030683]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accu.append(a_2)\n",
    "accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_models_rec,new_params_rec = get_new_models(init_models_2,init_params_2,harmony_matrix_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time 4.307210206985474\n",
      "0.9417781106027013\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "b_2 = final_harmony_search(new_models_rec,new_params_rec)\n",
    "end = time.time()\n",
    "print(\"time\",end - start)\n",
    "print(b_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9424847083981948, 0.9417781106027013]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accu_2.append(b_2)\n",
    "accu_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val=[8,30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9413353486275559, 0.9414763406030683]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9424847083981948, 0.9417781106027013]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accu_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Models 52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_models_3 = ['decision_tree','random_forest','linear_regression','logistic_regression','logistic_regression',\\\n",
    "               'random_forest','logistic_regression','decision_tree','linear_regression', 'random_forest', \\\n",
    "               'linear_regression','decision_tree','logistic_regression','decision_tree','random_forest',\\\n",
    "               'decision_tree', 'logistic_regression','linear_regression','random_forest','decision_tree', \\\n",
    "                'random_forest','linear_regression','logistic_regression','logistic_regression','random_forest',\\\n",
    "                'linear_regression','decision_tree','logistic_regression','decision_tree','random_forest',\\\n",
    "                 'decision_tree','random_forest','linear_regression','logistic_regression','logistic_regression',\\\n",
    "                 'random_forest','logistic_regression','decision_tree','linear_regression', 'random_forest', \\\n",
    "                 'linear_regression','decision_tree','logistic_regression','decision_tree','random_forest',\\\n",
    "                 'decision_tree', 'logistic_regression','linear_regression','random_forest','decision_tree',\\\n",
    "                 'logistic_regression','linear_regression'\n",
    "                ]\n",
    "init_params_3 = [param_dt, param_rf,param_lr, param_l2, param_l1,\n",
    "               param_r,param_l,param_d,param_lr,param_rf,\n",
    "               param_lr, param_dt,param_l,param_d,param_r,\n",
    "               param_dt, param_l2,param_lr,param_rf,param_d,\n",
    "               param_r,param_lr,param_l2, param_l,param_rf,\n",
    "               param_lr,param_dt,param_l2,param_dt,param_r,\n",
    "               param_dt, param_rf,param_lr, param_l2, param_l1,\n",
    "               param_r,param_l,param_d,param_lr,param_rf,\n",
    "               param_lr, param_dt,param_l,param_d,param_r,\n",
    "               param_dt, param_l2,param_lr,param_rf,param_d,\n",
    "               param_l,param_lr\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(init_params_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(init_models_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "harmony_matrix_1 = np.random.randint(2, size=(number_of_rows, len(init_models_3)))\n",
    "harmony_matrix_2 = np.random.randint(2, size=(number_of_rows, len(init_models_3)))\n",
    "harmony_matrix_3 = np.random.randint(2, size=(number_of_rows, len(init_models_3)))\n",
    "harmony_matrix_4 = np.random.randint(2, size=(number_of_rows, len(init_models_3)))\n",
    "harmony_matrix_5 = np.random.randint(2, size=(number_of_rows, len(init_models_3)))\n",
    "harmony_matrix_6 = np.random.randint(2, size=(number_of_rows, len(init_models_3)))\n",
    "harmony_matrix_7 = np.random.randint(2, size=(number_of_rows, len(init_models_3)))\n",
    "harmony_matrix_8 = np.random.randint(2, size=(number_of_rows, len(init_models_3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harmony Matrix 1\n",
      "[[0 0 1 0 0 0 1 0 0 1 1 0 1 1 1 0 0 1 0 0 1 1 0 1 1 1 0 0 1 0 0 0 1 1 1 0\n",
      "  0 0 1 0 0 0 0 1 0 1 0 1 0 0 0 1]\n",
      " [0 1 0 1 0 1 1 1 0 0 1 1 0 0 1 1 0 0 1 0 1 0 0 0 1 0 0 1 1 0 1 0 1 1 1 0\n",
      "  0 0 0 0 1 0 0 1 1 0 1 0 0 0 0 1]\n",
      " [1 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 1 1 0 0 0 1 1 0 1 1 1 0 0 0 1 0 0 1 0 1\n",
      "  1 1 1 0 1 1 0 1 0 0 1 1 1 1 0 1]\n",
      " [1 1 0 1 0 0 0 1 1 1 0 1 0 1 1 0 1 0 1 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0\n",
      "  0 1 1 0 0 0 1 1 1 0 1 0 1 1 1 1]\n",
      " [0 1 0 0 1 1 1 0 0 0 0 1 0 1 0 1 0 1 1 1 1 1 0 0 0 1 1 0 1 1 1 1 1 1 1 1\n",
      "  1 0 0 0 0 1 0 1 0 0 0 0 1 0 1 1]\n",
      " [0 0 0 0 0 0 1 1 1 1 1 1 0 0 1 0 0 1 1 0 1 1 0 1 1 0 0 0 0 0 0 1 1 0 0 1\n",
      "  0 1 0 1 1 1 1 0 1 0 0 1 1 0 1 0]\n",
      " [1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 0 0 1 0 0 1 0 0 0 0 1 1 0 0 0 1 1 0\n",
      "  1 1 0 1 1 1 1 0 0 0 1 0 1 1 1 1]]\n",
      "Harmony Matrix 2\n",
      "[[1 1 0 0 0 0 1 1 0 1 1 1 1 1 0 0 0 1 1 0 1 1 0 1 1 1 1 1 0 1 1 0 0 1 1 0\n",
      "  0 1 1 0 1 0 0 1 0 0 1 1 0 0 1 0]\n",
      " [1 1 1 0 1 1 0 1 1 0 0 0 1 1 0 1 0 1 1 0 1 1 0 0 1 0 1 1 0 0 1 1 1 0 1 0\n",
      "  0 1 0 1 1 0 1 1 1 0 1 0 0 1 1 0]\n",
      " [1 1 1 0 0 0 0 0 1 1 1 1 0 1 0 1 1 0 0 1 0 1 1 0 0 1 1 1 1 0 0 0 0 0 1 0\n",
      "  0 1 0 1 0 0 0 1 1 1 1 0 1 1 1 0]\n",
      " [1 1 0 0 1 1 1 1 0 0 1 1 0 0 1 0 0 1 1 1 0 0 1 1 1 1 1 0 0 1 1 1 0 0 0 1\n",
      "  0 0 1 0 0 0 0 1 0 1 0 1 1 0 1 0]\n",
      " [0 0 1 1 1 0 1 1 1 0 1 0 1 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 1 1 0 0 1 0 0\n",
      "  0 0 1 1 1 1 0 1 0 1 0 0 0 1 1 0]\n",
      " [1 1 0 0 0 1 0 0 0 0 0 1 1 0 0 0 1 1 1 0 0 1 0 1 0 0 1 1 1 0 1 1 0 0 1 1\n",
      "  0 0 0 1 0 0 1 0 1 0 0 1 1 0 0 0]\n",
      " [1 0 0 1 1 0 1 0 1 1 0 1 0 1 0 1 1 0 1 0 1 0 1 0 1 0 0 1 1 1 1 0 0 1 1 1\n",
      "  0 1 0 0 0 0 1 0 1 0 1 1 1 1 0 1]]\n",
      "Harmony Matrix 3\n",
      "[[1 0 1 0 0 1 1 1 0 1 0 1 0 0 1 1 1 1 0 1 0 0 1 0 1 1 0 0 1 1 0 1 1 1 1 1\n",
      "  0 1 1 0 0 1 0 1 0 1 1 0 1 1 1 0]\n",
      " [1 0 1 0 0 1 0 0 1 1 0 0 0 1 1 1 0 1 0 1 1 1 0 0 1 0 1 0 0 0 0 0 1 0 0 1\n",
      "  0 0 0 1 1 0 1 0 1 1 1 0 0 0 1 0]\n",
      " [1 1 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 0 1 0 1 0 1 1 1 1 0 1 0 1 1 1 0 1 1 1\n",
      "  0 1 0 0 0 0 1 0 1 1 1 0 1 1 1 1]\n",
      " [0 0 0 1 1 0 1 1 1 0 1 0 0 1 1 1 0 1 0 0 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1\n",
      "  0 1 0 0 1 1 0 1 0 1 1 1 0 1 0 0]\n",
      " [1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 0 0 1 0 1 0 1 0 1 1 1 0 1 0 1 0 0 1 1 1\n",
      "  1 1 1 1 0 0 0 0 1 0 1 1 0 1 0 0]\n",
      " [0 0 1 1 0 0 1 0 0 0 0 0 1 1 1 0 1 0 1 1 0 0 1 1 0 1 0 0 0 0 0 1 1 0 1 1\n",
      "  1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0]\n",
      " [1 0 0 1 1 0 0 0 0 1 0 1 1 0 1 0 0 0 1 1 1 1 1 0 1 0 0 0 0 1 1 0 1 0 0 0\n",
      "  1 0 0 1 0 1 0 0 0 0 1 1 0 1 1 1]]\n",
      "Harmony Matrix 4\n",
      "[[1 1 1 0 0 0 0 1 0 0 0 1 1 1 0 1 1 1 1 0 0 1 0 1 0 0 1 1 0 0 0 0 1 0 1 1\n",
      "  0 1 0 0 0 1 1 0 0 1 0 1 1 1 0 1]\n",
      " [1 1 0 0 0 0 1 1 1 0 0 1 0 1 1 0 1 1 0 0 0 1 0 0 0 1 1 0 1 1 0 1 1 0 0 0\n",
      "  1 1 0 1 1 0 0 1 0 0 1 0 0 0 0 0]\n",
      " [0 1 0 1 1 1 0 0 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 0 0 1\n",
      "  1 0 0 1 0 0 0 1 0 0 1 0 1 0 1 1]\n",
      " [1 1 0 1 0 0 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 0 0 0 1 1 1 0 0 0 0 1\n",
      "  1 1 1 0 1 0 1 0 0 0 0 1 0 1 1 1]\n",
      " [0 0 0 0 1 0 0 1 0 1 0 0 1 1 0 1 0 1 0 0 1 1 0 1 0 1 1 0 1 0 1 0 0 1 0 1\n",
      "  0 0 1 1 0 0 0 1 1 0 0 0 1 1 1 0]\n",
      " [1 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 0 0 1 1 0 0 1 1 1\n",
      "  1 1 0 1 0 1 0 1 0 0 0 0 1 0 0 1]\n",
      " [0 0 1 1 1 1 1 0 0 0 1 0 1 1 1 0 0 1 1 0 1 0 1 1 1 0 1 1 0 0 0 1 0 1 0 0\n",
      "  1 0 0 1 0 0 1 1 0 0 0 0 1 0 1 1]]\n",
      "Harmony Matrix 5\n",
      "[[0 1 0 0 0 1 0 0 0 0 0 1 0 1 0 1 0 1 1 0 0 0 0 0 0 1 0 0 1 1 1 0 0 0 0 0\n",
      "  1 1 1 1 0 0 1 1 0 1 1 1 0 0 1 0]\n",
      " [1 0 0 0 0 0 0 1 1 1 0 1 1 0 0 0 1 1 1 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0 1 0\n",
      "  1 0 0 1 0 1 1 1 0 1 0 1 0 1 1 1]\n",
      " [0 1 1 1 1 0 1 1 0 1 0 1 1 0 1 0 0 1 0 1 1 0 1 0 0 1 0 1 0 0 1 0 1 1 0 1\n",
      "  0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 1]\n",
      " [1 0 1 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 1 0 0 0 0 1 1 1 0 0 0 1 1 0 1 1 1 0\n",
      "  0 1 1 1 1 0 0 0 0 0 1 1 1 0 1 1]\n",
      " [1 0 0 0 0 1 0 1 0 1 1 0 0 0 0 1 0 0 0 1 1 0 1 0 1 1 0 0 0 1 0 0 1 0 0 1\n",
      "  0 0 0 0 0 1 1 1 0 0 0 0 1 1 0 1]\n",
      " [0 0 1 0 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 1 1 0 0 1 1 0 0 0 1 1 0 1 1 0 0 0\n",
      "  1 0 0 1 0 1 0 0 1 0 0 0 0 1 1 0]\n",
      " [0 0 1 0 1 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 0 1 0 0 0 1 1 0 0 1 1 1 0 0 1 1\n",
      "  1 0 1 0 1 0 0 0 0 1 0 0 0 1 0 1]]\n",
      "Harmony Matrix 6\n",
      "[[1 1 1 1 0 1 1 0 0 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1\n",
      "  0 0 0 1 1 1 0 0 0 0 0 1 0 0 0 1]\n",
      " [1 0 1 1 0 0 1 1 0 1 0 0 0 0 0 0 1 1 0 0 0 1 0 1 1 1 1 0 0 0 0 0 1 0 1 0\n",
      "  1 1 0 1 0 0 1 1 0 1 1 1 1 0 0 0]\n",
      " [0 1 1 0 1 1 0 0 1 1 1 0 0 1 1 0 1 0 0 0 1 1 0 0 1 0 0 0 0 0 0 1 1 0 0 1\n",
      "  1 0 1 1 0 1 0 0 1 0 0 1 0 1 0 1]\n",
      " [0 1 0 1 0 0 1 1 1 0 1 1 0 1 0 1 0 1 0 0 1 0 0 1 1 1 0 0 0 0 0 1 1 0 0 1\n",
      "  1 0 0 0 1 0 0 0 1 1 0 1 0 0 0 1]\n",
      " [1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 0 0 0 1 0 0 1 1 0 0 1 1\n",
      "  1 0 0 1 0 0 0 1 1 1 1 0 1 1 0 1]\n",
      " [0 0 0 1 1 0 0 1 0 1 0 1 1 1 0 1 0 0 1 1 1 1 1 1 0 0 1 0 1 1 1 0 0 0 1 0\n",
      "  0 1 1 0 0 1 0 1 0 0 0 0 0 0 1 1]\n",
      " [0 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 1 1 1 1 0 0 1 0 1 1 1 0 0 0 0 1\n",
      "  0 1 0 0 0 1 1 1 1 0 1 1 1 0 0 0]]\n",
      "Harmony Matrix 7\n",
      "[[0 0 1 0 0 1 0 1 1 0 1 0 0 1 0 0 0 1 1 1 0 0 0 0 1 1 1 1 1 1 1 0 1 0 1 0\n",
      "  0 0 1 1 1 0 1 1 0 1 0 1 0 1 0 1]\n",
      " [1 1 0 1 1 1 0 0 1 0 0 0 0 0 1 1 1 0 0 1 1 1 1 0 0 0 0 1 0 1 1 0 0 1 0 0\n",
      "  1 1 1 0 1 0 1 0 0 0 0 0 1 1 0 1]\n",
      " [0 1 1 1 0 1 0 0 1 1 0 1 1 0 0 1 1 1 0 1 1 1 0 0 0 1 1 1 0 1 1 1 1 1 0 1\n",
      "  1 1 0 0 1 0 1 0 1 0 1 1 0 1 0 0]\n",
      " [0 0 0 1 1 0 1 0 1 0 0 1 0 0 1 1 0 1 1 0 1 0 1 1 0 0 0 1 1 0 0 0 1 0 0 0\n",
      "  1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1]\n",
      " [0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 1 0 1 0 1 1 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1\n",
      "  0 1 0 1 0 0 0 0 1 1 0 0 0 1 1 0]\n",
      " [0 1 1 1 0 0 0 0 1 0 0 0 1 1 0 0 1 0 1 1 0 1 1 1 0 0 1 1 1 0 0 0 0 1 0 1\n",
      "  1 0 0 0 1 1 0 1 0 1 1 1 0 1 1 0]\n",
      " [1 0 0 0 0 1 0 0 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 1 1 0 1 0\n",
      "  0 1 0 1 0 0 0 0 1 0 1 0 0 1 0 0]]\n",
      "Harmony Matrix 8\n",
      "[[1 1 1 0 1 0 0 0 0 0 0 1 1 0 0 1 1 0 0 1 0 1 0 0 0 0 0 1 0 1 1 0 1 0 1 0\n",
      "  0 0 0 0 1 0 0 1 1 1 0 1 0 1 1 0]\n",
      " [1 0 0 0 1 1 0 1 0 1 0 0 0 1 1 1 1 0 1 0 0 1 1 1 0 0 0 1 0 1 1 1 1 1 1 0\n",
      "  0 1 1 0 0 0 1 0 1 0 1 1 0 1 1 1]\n",
      " [1 0 0 0 1 0 1 0 0 0 1 1 1 1 1 1 1 0 1 1 1 0 1 0 0 1 0 1 0 0 0 0 0 1 0 0\n",
      "  0 0 0 1 1 1 1 1 1 0 1 1 1 1 0 0]\n",
      " [1 0 1 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 0 0 1 0 1 1 0 1 1 1 0 1 0 0 0 0 0 1\n",
      "  0 0 1 1 1 1 1 1 1 1 1 0 0 1 0 0]\n",
      " [0 1 1 1 1 1 0 1 0 0 1 1 1 1 0 1 1 0 0 0 1 0 1 0 0 0 1 1 1 1 0 0 0 1 0 0\n",
      "  1 0 0 1 1 0 1 1 0 1 0 1 0 0 0 1]\n",
      " [0 1 0 0 1 1 1 1 1 1 1 0 1 0 1 0 0 1 1 0 0 0 0 1 1 0 1 0 0 0 0 1 1 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0]\n",
      " [0 1 1 0 0 1 0 0 1 1 1 1 1 0 0 1 0 0 0 1 1 0 0 0 1 0 1 1 1 0 1 0 0 0 0 1\n",
      "  0 1 1 1 0 0 0 1 1 0 0 0 1 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Harmony Matrix 1\")\n",
    "print(harmony_matrix_1)\n",
    "print(\"Harmony Matrix 2\")\n",
    "print(harmony_matrix_2)\n",
    "print(\"Harmony Matrix 3\")\n",
    "print(harmony_matrix_3)\n",
    "print(\"Harmony Matrix 4\")\n",
    "print(harmony_matrix_4)\n",
    "print(\"Harmony Matrix 5\")\n",
    "print(harmony_matrix_5)\n",
    "print(\"Harmony Matrix 6\")\n",
    "print(harmony_matrix_6)\n",
    "print(\"Harmony Matrix 7\")\n",
    "print(harmony_matrix_7)\n",
    "print(\"Harmony Matrix 8\")\n",
    "print(harmony_matrix_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Harmony Matrix\n",
      "[[0 0 1 0 0 0 1 0 0 1 1 0 1 1 1 0 0 1 0 0 1 1 0 1 1 1 0 0 1 0 0 0 1 1 1 0\n",
      "  0 0 1 0 0 0 0 1 0 1 0 1 0 0 0 1]\n",
      " [0 1 0 1 0 1 1 1 0 0 1 1 0 0 1 1 0 0 1 0 1 0 0 0 1 0 0 1 1 0 1 0 1 1 1 0\n",
      "  0 0 0 0 1 0 0 1 1 0 1 0 0 0 0 1]\n",
      " [0 1 1 1 0 1 1 1 0 1 1 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1\n",
      "  1 1 1 0 0 0 0 1 1 0 1 1 0 0 1 1]\n",
      " [1 1 0 1 0 0 0 1 1 1 0 1 0 1 1 0 1 0 1 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0\n",
      "  0 1 1 0 0 0 1 1 1 0 1 0 1 1 1 1]\n",
      " [0 1 0 0 1 1 1 0 0 0 0 1 0 1 0 1 0 1 1 1 1 1 0 0 0 1 1 0 1 1 1 1 1 1 1 1\n",
      "  1 0 0 0 0 1 0 1 0 0 0 0 1 0 1 1]\n",
      " [0 0 0 0 0 0 1 1 1 1 1 1 0 0 1 0 0 1 1 0 1 1 0 1 1 0 0 0 0 0 0 1 1 0 0 1\n",
      "  0 1 0 1 1 1 1 0 1 0 0 1 1 0 1 0]\n",
      " [1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 0 0 1 0 0 1 0 0 0 0 1 1 0 0 0 1 1 0\n",
      "  1 1 0 1 1 1 1 0 0 0 1 0 1 1 1 1]]\n",
      "Optimal Harmony Matrix\n",
      "[[0 1 0 1 0 1 1 1 0 0 1 1 0 0 1 1 0 0 1 0 1 0 0 0 1 0 0 1 1 0 1 0 1 1 1 0\n",
      "  0 0 0 0 1 0 0 1 1 0 1 0 0 0 0 1]]\n",
      "Final Harmony Matrix\n",
      "[[1 1 0 0 0 0 1 1 0 1 1 1 1 1 0 0 0 1 1 0 1 1 0 1 1 1 1 1 0 1 1 0 0 1 1 0\n",
      "  0 1 1 0 1 0 0 1 0 0 1 1 0 0 1 0]\n",
      " [1 1 1 0 1 1 0 1 1 0 0 0 1 1 0 1 0 1 1 0 1 1 0 0 1 0 1 1 0 0 1 1 1 0 1 0\n",
      "  0 1 0 1 1 0 1 1 1 0 1 0 0 1 1 0]\n",
      " [1 1 1 0 0 0 0 0 1 1 1 1 0 1 0 1 1 0 0 1 0 1 1 0 0 1 1 1 1 0 0 0 0 0 1 0\n",
      "  0 1 0 1 0 0 0 1 1 1 1 0 1 1 1 0]\n",
      " [1 1 0 0 1 1 1 1 0 0 1 1 0 0 1 0 0 1 1 1 0 0 1 1 1 1 1 0 0 1 1 1 0 0 0 1\n",
      "  0 0 1 0 0 0 0 1 0 1 0 1 1 0 1 0]\n",
      " [0 1 1 1 0 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 1 1 0 1 0 0 1 1 1 1 0 0 1 1 0 1\n",
      "  1 0 0 1 1 0 1 1 1 0 1 0 0 1 1 1]\n",
      " [1 1 0 0 0 1 0 0 0 0 0 1 1 0 0 0 1 1 1 0 0 1 0 1 0 0 1 1 1 0 1 1 0 0 1 1\n",
      "  0 0 0 1 0 0 1 0 1 0 0 1 1 0 0 0]\n",
      " [1 0 0 1 1 0 1 0 1 1 0 1 0 1 0 1 1 0 1 0 1 0 1 0 1 0 0 1 1 1 1 0 0 1 1 1\n",
      "  0 1 0 0 0 0 1 0 1 0 1 1 1 1 0 1]]\n",
      "Optimal Harmony Matrix\n",
      "[[0 1 1 1 0 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 1 1 0 1 0 0 1 1 1 1 0 0 1 1 0 1\n",
      "  1 0 0 1 1 0 1 1 1 0 1 0 0 1 1 1]]\n",
      "Final Harmony Matrix\n",
      "[[1 0 1 0 0 1 1 1 0 1 0 1 0 0 1 1 1 1 0 1 0 0 1 0 1 1 0 0 1 1 0 1 1 1 1 1\n",
      "  0 1 1 0 0 1 0 1 0 1 1 0 1 1 1 0]\n",
      " [1 0 1 0 0 1 0 0 1 1 0 0 0 1 1 1 0 1 0 1 1 1 0 0 1 0 1 0 0 0 0 0 1 0 0 1\n",
      "  0 0 0 1 1 0 1 0 1 1 1 0 0 0 1 0]\n",
      " [1 1 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 0 1 0 1 0 1 1 1 1 0 1 0 1 1 1 0 1 1 1\n",
      "  0 1 0 0 0 0 1 0 1 1 1 0 1 1 1 1]\n",
      " [0 0 0 1 1 0 1 1 1 0 1 0 0 1 1 1 0 1 0 0 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1\n",
      "  0 1 0 0 1 1 0 1 0 1 1 1 0 1 0 0]\n",
      " [1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 0 0 1 0 1 0 1 0 1 1 1 0 1 0 1 0 0 1 1 1\n",
      "  1 1 1 1 0 0 0 0 1 0 1 1 0 1 0 0]\n",
      " [0 1 0 0 1 1 1 1 0 1 1 1 1 1 1 0 0 1 0 1 0 1 0 0 1 0 1 0 1 0 0 1 1 0 0 1\n",
      "  0 0 1 1 0 0 0 0 0 0 0 1 1 1 1 1]\n",
      " [1 0 0 1 1 0 0 0 0 1 0 1 1 0 1 0 0 0 1 1 1 1 1 0 1 0 0 0 0 1 1 0 1 0 0 0\n",
      "  1 0 0 1 0 1 0 0 0 0 1 1 0 1 1 1]]\n",
      "Optimal Harmony Matrix\n",
      "[[1 0 0 1 1 0 0 0 0 1 0 1 1 0 1 0 0 0 1 1 1 1 1 0 1 0 0 0 0 1 1 0 1 0 0 0\n",
      "  1 0 0 1 0 1 0 0 0 0 1 1 0 1 1 1]]\n",
      "Final Harmony Matrix\n",
      "[[1 1 0 1 0 1 1 0 1 1 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0 1 1 1 0 0 0 0 0 1\n",
      "  0 0 1 0 1 1 0 0 1 1 0 0 0 1 1 1]\n",
      " [1 1 0 0 0 0 1 1 1 0 0 1 0 1 1 0 1 1 0 0 0 1 0 0 0 1 1 0 1 1 0 1 1 0 0 0\n",
      "  1 1 0 1 1 0 0 1 0 0 1 0 0 0 0 0]\n",
      " [0 1 0 1 1 1 0 0 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 0 0 1\n",
      "  1 0 0 1 0 0 0 1 0 0 1 0 1 0 1 1]\n",
      " [1 1 0 1 0 0 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 0 0 0 1 1 1 0 0 0 0 1\n",
      "  1 1 1 0 1 0 1 0 0 0 0 1 0 1 1 1]\n",
      " [0 0 0 0 1 0 0 1 0 1 0 0 1 1 0 1 0 1 0 0 1 1 0 1 0 1 1 0 1 0 1 0 0 1 0 1\n",
      "  0 0 1 1 0 0 0 1 1 0 0 0 1 1 1 0]\n",
      " [1 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 0 0 1 1 0 0 1 1 1\n",
      "  1 1 0 1 0 1 0 1 0 0 0 0 1 0 0 1]\n",
      " [0 0 1 1 1 1 1 0 0 0 1 0 1 1 1 0 0 1 1 0 1 0 1 1 1 0 1 1 0 0 0 1 0 1 0 0\n",
      "  1 0 0 1 0 0 1 1 0 0 0 0 1 0 1 1]]\n",
      "Optimal Harmony Matrix\n",
      "[[1 1 0 1 0 1 1 0 1 1 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0 1 1 1 0 0 0 0 0 1\n",
      "  0 0 1 0 1 1 0 0 1 1 0 0 0 1 1 1]]\n",
      "Final Harmony Matrix\n",
      "[[0 1 0 0 0 1 0 0 0 0 0 1 0 1 0 1 0 1 1 0 0 0 0 0 0 1 0 0 1 1 1 0 0 0 0 0\n",
      "  1 1 1 1 0 0 1 1 0 1 1 1 0 0 1 0]\n",
      " [1 1 0 1 0 1 1 1 0 1 1 0 0 1 0 0 1 1 1 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0 1 1\n",
      "  0 1 0 0 0 0 1 0 1 0 1 0 1 0 1 0]\n",
      " [0 1 1 1 1 0 1 1 0 1 0 1 1 0 1 0 0 1 0 1 1 0 1 0 0 1 0 1 0 0 1 0 1 1 0 1\n",
      "  0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 1]\n",
      " [1 0 1 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 1 0 0 0 0 1 1 1 0 0 0 1 1 0 1 1 1 0\n",
      "  0 1 1 1 1 0 0 0 0 0 1 1 1 0 1 1]\n",
      " [1 0 0 0 0 1 0 1 0 1 1 0 0 0 0 1 0 0 0 1 1 0 1 0 1 1 0 0 0 1 0 0 1 0 0 1\n",
      "  0 0 0 0 0 1 1 1 0 0 0 0 1 1 0 1]\n",
      " [0 0 1 0 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 1 1 0 0 1 1 0 0 0 1 1 0 1 1 0 0 0\n",
      "  1 0 0 1 0 1 0 0 1 0 0 0 0 1 1 0]\n",
      " [0 0 1 0 1 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 0 1 0 0 0 1 1 0 0 1 1 1 0 0 1 1\n",
      "  1 0 1 0 1 0 0 0 0 1 0 0 0 1 0 1]]\n",
      "Optimal Harmony Matrix\n",
      "[[0 1 0 0 0 1 0 0 0 0 0 1 0 1 0 1 0 1 1 0 0 0 0 0 0 1 0 0 1 1 1 0 0 0 0 0\n",
      "  1 1 1 1 0 0 1 1 0 1 1 1 0 0 1 0]]\n",
      "Final Harmony Matrix\n",
      "[[1 1 1 1 0 1 1 0 0 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1\n",
      "  0 0 0 1 1 1 0 0 0 0 0 1 0 0 0 1]\n",
      " [0 1 0 0 1 0 0 1 1 0 0 0 1 0 1 1 1 1 0 0 1 1 0 0 0 1 0 0 1 1 0 0 0 0 0 1\n",
      "  1 1 1 0 0 0 0 1 0 0 1 0 1 1 1 1]\n",
      " [0 1 1 0 1 1 0 0 1 1 1 0 0 1 1 0 1 0 0 0 1 1 0 0 1 0 0 0 0 0 0 1 1 0 0 1\n",
      "  1 0 1 1 0 1 0 0 1 0 0 1 0 1 0 1]\n",
      " [0 1 0 1 0 0 1 1 1 0 1 1 0 1 0 1 0 1 0 0 1 0 0 1 1 1 0 0 0 0 0 1 1 0 0 1\n",
      "  1 0 0 0 1 0 0 0 1 1 0 1 0 0 0 1]\n",
      " [1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 0 0 0 1 0 0 1 1 0 0 1 1\n",
      "  1 0 0 1 0 0 0 1 1 1 1 0 1 1 0 1]\n",
      " [0 0 0 1 1 0 0 1 0 1 0 1 1 1 0 1 0 0 1 1 1 1 1 1 0 0 1 0 1 1 1 0 0 0 1 0\n",
      "  0 1 1 0 0 1 0 1 0 0 0 0 0 0 1 1]\n",
      " [0 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 1 1 1 1 0 0 1 0 1 1 1 0 0 0 0 1\n",
      "  0 1 0 0 0 1 1 1 1 0 1 1 1 0 0 0]]\n",
      "Optimal Harmony Matrix\n",
      "[[1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 0 0 0 1 0 0 1 1 0 0 1 1\n",
      "  1 0 0 1 0 0 0 1 1 1 1 0 1 1 0 1]]\n",
      "Final Harmony Matrix\n",
      "[[0 0 1 0 0 1 0 1 1 0 1 0 0 1 0 0 0 1 1 1 0 0 0 0 1 1 1 1 1 1 1 0 1 0 1 0\n",
      "  0 0 1 1 1 0 1 1 0 1 0 1 0 1 0 1]\n",
      " [1 1 0 1 1 1 0 0 1 0 0 0 0 0 1 1 1 0 0 1 1 1 1 0 0 0 0 1 0 1 1 0 0 1 0 0\n",
      "  1 1 1 0 1 0 1 0 0 0 0 0 1 1 0 1]\n",
      " [0 1 1 1 0 1 0 0 1 1 0 1 1 0 0 1 1 1 0 1 1 1 0 0 0 1 1 1 0 1 1 1 1 1 0 1\n",
      "  1 1 0 0 1 0 1 0 1 0 1 1 0 1 0 0]\n",
      " [0 0 0 1 1 0 1 0 1 0 0 1 0 0 1 1 0 1 1 0 1 0 1 1 0 0 0 1 1 0 0 0 1 0 0 0\n",
      "  1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1]\n",
      " [0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 1 0 1 0 1 1 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1\n",
      "  0 1 0 1 0 0 0 0 1 1 0 0 0 1 1 0]\n",
      " [1 0 0 0 1 0 0 0 1 0 1 0 0 1 1 0 1 1 1 0 0 1 0 1 0 1 0 0 1 0 1 1 0 1 0 0\n",
      "  0 1 0 1 0 1 1 1 0 0 1 0 1 0 0 1]\n",
      " [1 0 0 0 0 1 0 0 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 1 1 0 1 0\n",
      "  0 1 0 1 0 0 0 0 1 0 1 0 0 1 0 0]]\n",
      "Optimal Harmony Matrix\n",
      "[[1 0 0 0 0 1 0 0 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 1 1 0 1 0\n",
      "  0 1 0 1 0 0 0 0 1 0 1 0 0 1 0 0]]\n",
      "Final Harmony Matrix\n",
      "[[0 1 1 1 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 1 1 0 0 0 0 1 1 1 1 0 0 0 1 0 1\n",
      "  1 0 0 0 1 1 1 1 1 1 1 1 0 1 0 1]\n",
      " [1 0 0 0 1 1 0 1 0 1 0 0 0 1 1 1 1 0 1 0 0 1 1 1 0 0 0 1 0 1 1 1 1 1 1 0\n",
      "  0 1 1 0 0 0 1 0 1 0 1 1 0 1 1 1]\n",
      " [1 0 0 0 1 0 1 0 0 0 1 1 1 1 1 1 1 0 1 1 1 0 1 0 0 1 0 1 0 0 0 0 0 1 0 0\n",
      "  0 0 0 1 1 1 1 1 1 0 1 1 1 1 0 0]\n",
      " [1 0 1 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 0 0 1 0 1 1 0 1 1 1 0 1 0 0 0 0 0 1\n",
      "  0 0 1 1 1 1 1 1 1 1 1 0 0 1 0 0]\n",
      " [0 1 1 1 1 1 0 1 0 0 1 1 1 1 0 1 1 0 0 0 1 0 1 0 0 0 1 1 1 1 0 0 0 1 0 0\n",
      "  1 0 0 1 1 0 1 1 0 1 0 1 0 0 0 1]\n",
      " [0 1 0 0 1 1 1 1 1 1 1 0 1 0 1 0 0 1 1 0 0 0 0 1 1 0 1 0 0 0 0 1 1 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0]\n",
      " [0 1 1 0 0 1 0 0 1 1 1 1 1 0 0 1 0 0 0 1 1 0 0 0 1 0 1 1 1 0 1 0 0 0 0 1\n",
      "  0 1 1 1 0 0 0 1 1 0 0 0 1 1 0 0]]\n",
      "Optimal Harmony Matrix\n",
      "[[1 0 0 0 1 1 0 1 0 1 0 0 0 1 1 1 1 0 1 0 0 1 1 1 0 0 0 1 0 1 1 1 1 1 1 0\n",
      "  0 1 1 0 0 0 1 0 1 0 1 1 0 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "predict_list,data_X,data_Y = train_base_models(init_models_3,init_params_3)\n",
    "\n",
    "harmony_matrix_1 = hs(harmony_matrix_1)\n",
    "harmony_matrix_2 = hs(harmony_matrix_2)\n",
    "harmony_matrix_3 = hs(harmony_matrix_3)\n",
    "harmony_matrix_4 = hs(harmony_matrix_4)\n",
    "harmony_matrix_5 = hs(harmony_matrix_5)\n",
    "harmony_matrix_6 = hs(harmony_matrix_6)\n",
    "harmony_matrix_7 = hs(harmony_matrix_7)\n",
    "harmony_matrix_8 = hs(harmony_matrix_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recursive Harmony Matrix\n",
      "[[0 1 0 1 0 1 1 1 0 0 1 1 0 0 1 1 0 0 1 0 1 0 0 0 1 0 0 1 1 0 1 0 1 1 1 0\n",
      "  0 0 0 0 1 0 0 1 1 0 1 0 0 0 0 1]\n",
      " [0 1 1 1 0 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 1 1 0 1 0 0 1 1 1 1 0 0 1 1 0 1\n",
      "  1 0 0 1 1 0 1 1 1 0 1 0 0 1 1 1]\n",
      " [1 0 0 1 1 0 0 0 0 1 0 1 1 0 1 0 0 0 1 1 1 1 1 0 1 0 0 0 0 1 1 0 1 0 0 0\n",
      "  1 0 0 1 0 1 0 0 0 0 1 1 0 1 1 1]\n",
      " [1 1 0 1 0 1 1 0 1 1 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0 1 1 1 0 0 0 0 0 1\n",
      "  0 0 1 0 1 1 0 0 1 1 0 0 0 1 1 1]\n",
      " [0 1 0 0 0 1 0 0 0 0 0 1 0 1 0 1 0 1 1 0 0 0 0 0 0 1 0 0 1 1 1 0 0 0 0 0\n",
      "  1 1 1 1 0 0 1 1 0 1 1 1 0 0 1 0]\n",
      " [1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 0 0 0 1 0 0 1 1 0 0 1 1\n",
      "  1 0 0 1 0 0 0 1 1 1 1 0 1 1 0 1]\n",
      " [1 0 0 0 0 1 0 0 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 1 1 0 1 0\n",
      "  0 1 0 1 0 0 0 0 1 0 1 0 0 1 0 0]\n",
      " [1 0 0 0 1 1 0 1 0 1 0 0 0 1 1 1 1 0 1 0 0 1 1 1 0 0 0 1 0 1 1 1 1 1 1 0\n",
      "  0 1 1 0 0 0 1 0 1 0 1 1 0 1 1 1]]\n",
      "Final Harmony Matrix\n",
      "[[0 1 0 1 0 1 1 1 0 0 1 1 0 0 1 1 0 0 1 0 1 0 0 0 1 0 0 1 1 0 1 0 1 1 1 0\n",
      "  0 0 0 0 1 0 0 1 1 0 1 0 0 0 0 1]\n",
      " [0 0 1 1 0 0 1 0 0 0 1 0 0 1 0 1 0 0 1 0 0 1 0 0 1 1 1 0 0 0 0 1 0 1 0 0\n",
      "  0 0 0 0 1 1 1 1 0 0 1 1 1 1 1 0]\n",
      " [1 0 0 1 1 0 0 0 0 1 0 1 1 0 1 0 0 0 1 1 1 1 1 0 1 0 0 0 0 1 1 0 1 0 0 0\n",
      "  1 0 0 1 0 1 0 0 0 0 1 1 0 1 1 1]\n",
      " [1 1 0 1 0 1 1 0 1 1 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0 1 1 1 0 0 0 0 0 1\n",
      "  0 0 1 0 1 1 0 0 1 1 0 0 0 1 1 1]\n",
      " [0 1 0 0 0 1 0 0 0 0 0 1 0 1 0 1 0 1 1 0 0 0 0 0 0 1 0 0 1 1 1 0 0 0 0 0\n",
      "  1 1 1 1 0 0 1 1 0 1 1 1 0 0 1 0]\n",
      " [1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 0 0 0 1 0 0 1 1 0 0 1 1\n",
      "  1 0 0 1 0 0 0 1 1 1 1 0 1 1 0 1]\n",
      " [1 0 0 0 0 1 0 0 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 1 1 0 1 0\n",
      "  0 1 0 1 0 0 0 0 1 0 1 0 0 1 0 0]\n",
      " [1 0 0 0 1 1 0 1 0 1 0 0 0 1 1 1 1 0 1 0 0 1 1 1 0 0 0 1 0 1 1 1 1 1 1 0\n",
      "  0 1 1 0 0 0 1 0 1 0 1 1 0 1 1 1]]\n",
      "Optimal Harmony Matrix\n",
      "[[1 0 0 0 1 1 0 1 0 1 0 0 0 1 1 1 1 0 1 0 0 1 1 1 0 0 0 1 0 1 1 1 1 1 1 0\n",
      "  0 1 1 0 0 0 1 0 1 0 1 1 0 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "harmony_matrix_rec = np.concatenate((harmony_matrix_1,harmony_matrix_2,harmony_matrix_3,harmony_matrix_4,\\\n",
    "                                    harmony_matrix_5,harmony_matrix_6,harmony_matrix_7,harmony_matrix_8))\n",
    "print(\"Recursive Harmony Matrix\")\n",
    "print(harmony_matrix_rec)\n",
    "harmony_matrix_rec = hs(harmony_matrix_rec)                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time 117.82081604003906\n",
      "0.9414551787033977\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "a_3 = final_harmony_search(init_models_3,init_params_3)\n",
    "end = time.time()\n",
    "print(\"time\",end - start)\n",
    "print(a_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9413353486275559, 0.9414763406030683, 0.9414551787033977]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accu.append(a_3)\n",
    "accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_models_rec,new_params_rec = get_new_models(init_models_3,init_params_3,harmony_matrix_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time 101.21199083328247\n",
      "0.9416236221834362\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "b_3 = final_harmony_search(new_models_rec,new_params_rec)\n",
    "end = time.time()\n",
    "print(\"time\",end - start)\n",
    "print(b_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9424847083981948, 0.9417781106027013, 0.9416236221834362]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accu_2.append(b_3)\n",
    "accu_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val=[8,30,52]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9413353486275559, 0.9414763406030683, 0.9414551787033977]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9424847083981948, 0.9417781106027013, 0.9416236221834362]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accu_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For plotting purpose of CPU time, we have stored above cpu time values in the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "CPU_time_without_reduction=[94.00571298599243,55.460633754730225,117.82081604003906]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[94.00571298599243, 55.460633754730225, 117.82081604003906]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CPU_time_without_reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "CPU_time_with_reduction=[77.79203200340271,4.307210206985474,101.21199083328247]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[77.79203200340271, 4.307210206985474, 101.21199083328247]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CPU_time_with_reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble Classifiers\n",
    "\n",
    "| Number of Models| Accuracy | CPU Time |\n",
    "| --- | --- | --- |\n",
    "| 8 | 0.94133 | 94.00 |\n",
    "| 30 | 0.94147 | 55.46 |\n",
    "| 52 | 0.94145 | 117.82 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble Classifiers Reduction\n",
    "\n",
    "| Number of Models| Accuracy | CPU Time |\n",
    "| --- | --- | --- |\n",
    "| 5 | 0.94248 | 77.79 |\n",
    "| 12 | 0.94177 | 4.30|\n",
    "| 29 | 0.94162 |101.21 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results show the performance of a reduced ensemble\n",
    "classifier against the performance of the original ensemble\n",
    "classifier. In all cases, the reduced ensemble classifier requires\n",
    "lesser memory and has a faster CPU run time, thereby reducing system overhead. The accuracy of the reduced ensemble\n",
    "classifier is either greater than, or almost equal to that of the\n",
    "original classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "● There are two tables of performance for dataset, the first table shows the performance without applying classifier ensemble reduction and the second shows the performance after classifier ensemble reduction. <br>\n",
    "● For example (bank dataset),\n",
    "- The first table shows that for an ensemble classifier with all 8 models, the accuracy is 0.94133 and CPU Run-time is 94s,\n",
    "- The second table shows that on applying classifier ensemble reduction, the number of models reduces from 8 to 5 (subset of 8) and the accuracy of training with 5 models is 0.94248 and the run time decreases to 77.79 seconds.<br>\n",
    "\n",
    "● 30 reduces to 12, and 52 reduces to 29 on applying the recursive harmony search feature selection algorithm (classifier ensemble reduction)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib.pylab import plt \n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(13,10))\n",
    "plt.plot(x_val, accu, '-', color=\"r\",marker='o', label=\"without classifier ensemble reduction\")\n",
    "plt.plot(x_val, accu_2, '-', color=\"b\", marker='o',label=\"Classifier ensemble reduction\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "\n",
    "plt.title(\"Accuracy after applying CER [Bank Dataset]\", fontsize=16, fontweight='bold')\n",
    "plt.xlabel(\"Number of models\")\n",
    "plt.ylabel(\"Accuracy (AUC Score)\")\n",
    "xte=[8,30,52]\n",
    "my_xticks = ['8(5)','30(12)','52(29)']\n",
    "plt.xticks(xte, my_xticks)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the reduced ensemble classifier is greater than of the original classifier in all cases.\n",
    "X axis lables is number of models. for e.g 8(5).Here 8 shows number of models we have taken and 5 shows number of models are after reduction using recursiver harmony search algorithm. <br>\n",
    "y axis shows AUC score for checking accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(13,10))\n",
    "plt.plot(x_val, CPU_time_without_reduction, '-',marker='o', color=\"r\", label=\"without classifier ensemble reduction\")\n",
    "plt.plot(x_val, CPU_time_with_reduction, '-',marker='o', color=\"b\", label=\"Classifier ensemble reduction\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "\n",
    "plt.title(\"CPU Runtime after applying CER [Bank Dataset]\", fontsize=16, fontweight='bold')\n",
    "plt.xlabel(\"Number of models\")\n",
    "plt.ylabel(\"CPU Time (Seconds)\")\n",
    "xte=[8,30,52]\n",
    "my_xticks = ['8(5)','30(12)','52(29)']\n",
    "plt.xticks(xte, my_xticks)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph shows how cpu runtime varies when we take different number of models. In all cases, the reduced ensemble classifier has a faster CPU run time, thereby reducing system overhead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have also implemented and tested the recursive harmony search feature selection algorithm again <b> The Heart Dataset</b>. Results of which are as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble Classifiers\n",
    "\n",
    "| Number of Models| Accuracy | CPU Time |\n",
    "| --- | --- | --- |\n",
    "| 8 | 0.9004 | 31.00 |\n",
    "| 30 | 0.9014 | 28.43|\n",
    "| 52 | 0.9087 | 45.79 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble Classifiers Reduction\n",
    "\n",
    "| Number of Models| Accuracy | CPU Time |\n",
    "| --- | --- | --- |\n",
    "| 4 | 0.9087 | 28.76 |\n",
    "| 15 | 0.9058 |21.28|\n",
    "| 30 | 0.9097 |41.19 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://user-images.githubusercontent.com/59700753/102702972-fde14c00-4236-11eb-8fe7-15548a7aebdd.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/59700753/102702990-34b76200-4237-11eb-9338-c18d0777d8c0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "● The recursive classifier ensemble reduction results in a reduced subset of classifiers that\n",
    "are used to train the ensemble classifier. This reduced set of the ensemble classifiers\n",
    "eliminates redundancy and is shown to run faster than the original set of the ensemble\n",
    "classifier.\n",
    "\n",
    "● The recursive classifier ensemble reduction technique minimizes redundancy, maintains and\n",
    "improves diversity and accuracy, and reduces system memory and run time requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "https://ieeexplore.ieee.org/document/8663245 <br>\n",
    "https://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/springerEBR09.pdf <br>\n",
    "https://www.analyticsvidhya.com/blog/2018/06/comprehensive-guide-for-ensemble-models/ <br>\n",
    "https://blog.statsbot.co/ensemble-learning-d1dcd548e936 <br>\n",
    "https://towardsdatascience.com/ensemble-methods-in-machine-learning-what-are-they-and-why-use-them-68ec3f9fef5f <br>\n",
    "https://www.degruyter.com/view/journals/jisys/27/3/article-p465.xml?language=en <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MIT License**\n",
    "\n",
    "Copyright (C) 2020 Shalini Chandra & Shubham Mahajan\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
